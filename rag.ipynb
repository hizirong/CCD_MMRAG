{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zirong/miniforge3/envs/llm/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from IPython.display import Image, display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image as VertexImage\n",
    "import vertexai\n",
    "import PyPDF2\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 檢查並創建必要的目錄\n",
    "Path('embeddings').mkdir(exist_ok=True)\n",
    "Path('image').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 資料處理和 Embedding 生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, text_model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        self.text_model = SentenceTransformer(text_model_name)\n",
    "        \n",
    "    def process_pdf(self, pdf_path: str) -> List[Dict]:\n",
    "        \"\"\"處理 PDF 文件\"\"\"\n",
    "        logger.info(f\"Processing PDF: {pdf_path}\")\n",
    "        documents = []\n",
    "        \n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    text = page.extract_text()\n",
    "                    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "                    \n",
    "                    for para in paragraphs:\n",
    "                        documents.append({\n",
    "                            'content': para,\n",
    "                            'metadata': {\n",
    "                                'source': pdf_path,\n",
    "                                'page': page_num + 1,\n",
    "                                'type': 'pdf'\n",
    "                            }\n",
    "                        })\n",
    "            \n",
    "            logger.info(f\"Extracted {len(documents)} paragraphs from PDF\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF {pdf_path}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def process_csv(self, csv_path: str, image_dir: str = \"image\") -> List[Dict]:\n",
    "        \"\"\"處理 CSV 檔案和相關圖片\"\"\"\n",
    "        logger.info(f\"Processing CSV: {csv_path}\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        posts = []\n",
    "        current_post = None\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            if pd.notna(row['post']):\n",
    "                if current_post:\n",
    "                    posts.append({\n",
    "                        'content': current_post,\n",
    "                        'metadata': {'type': 'social_post'}\n",
    "                    })\n",
    "                current_post = {\n",
    "                    'post': row['post'],\n",
    "                    'responses': [],\n",
    "                    'images': [],\n",
    "                    'link': row['link'] if pd.notna(row['link']) else None\n",
    "                }\n",
    "            \n",
    "            if pd.notna(row['responses']):\n",
    "                current_post['responses'].append(row['responses'])\n",
    "            \n",
    "            # 處理圖片\n",
    "            if pd.notna(row.get('images')):\n",
    "                image_path = Path(image_dir) / row['images']\n",
    "                if image_path.exists():\n",
    "                    current_post['images'].append(row['images'])\n",
    "                    logger.info(f\"Added image: {row['images']}\")\n",
    "        \n",
    "        if current_post:\n",
    "            posts.append({\n",
    "                'content': current_post,\n",
    "                'metadata': {'type': 'social_post'}\n",
    "            })\n",
    "        \n",
    "        logger.info(f\"Processed {len(posts)} posts from CSV\")\n",
    "        return posts\n",
    "\n",
    "    def create_embeddings(self, documents: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"為文件生成 embeddings\"\"\"\n",
    "        embedded_docs = []\n",
    "        \n",
    "        for doc in documents:\n",
    "            if doc['metadata']['type'] == 'pdf':\n",
    "                text = doc['content']\n",
    "            else:  # social_post\n",
    "                content = doc['content']\n",
    "                text = f\"{content['post']} {' '.join(content['responses'])}\"\n",
    "            \n",
    "            embedding = self.text_model.encode(text)\n",
    "            \n",
    "            embedded_docs.append({\n",
    "                'text_embedding': embedding.tolist(),\n",
    "                'content': doc['content'],\n",
    "                'metadata': doc['metadata']\n",
    "            })\n",
    "        \n",
    "        return embedded_docs\n",
    "\n",
    "    def process_and_save(self, \n",
    "                        csv_path: str, \n",
    "                        pdf_path: str,\n",
    "                        save_path: str = 'embeddings/embeddings.json'):\n",
    "        \"\"\"處理所有資料並保存 embeddings\"\"\"\n",
    "        # 處理 PDF\n",
    "        pdf_docs = self.process_pdf(pdf_path)\n",
    "        \n",
    "        # 處理 CSV\n",
    "        csv_docs = self.process_csv(csv_path)\n",
    "        \n",
    "        # 合併文件\n",
    "        all_docs = pdf_docs + csv_docs\n",
    "        \n",
    "        # 生成 embeddings\n",
    "        embedded_docs = self.create_embeddings(all_docs)\n",
    "        \n",
    "        # 保存結果\n",
    "        with open(save_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(embedded_docs, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        logger.info(f\"Saved {len(embedded_docs)} embedded documents to {save_path}\")\n",
    "        return embedded_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. RAG 系統實作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiModalRAGSystem:\n",
    "    def __init__(self, \n",
    "                 project_id: str,\n",
    "                 location: str = \"us-central1\",\n",
    "                 image_dir: str = \"image\"):\n",
    "        \n",
    "        self.image_dir = Path(image_dir)\n",
    "        \n",
    "        # 設定 Google Cloud 憑證\n",
    "        if 'GOOGLE_APPLICATION_CREDENTIALS' not in os.environ:\n",
    "            os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = 'key/gemini-key.json'\n",
    "            \n",
    "        # 初始化 Vertex AI\n",
    "        vertexai.init(project=project_id, location=location)\n",
    "        self.llm = GenerativeModel('gemini-1.0-pro-vision-001')\n",
    "        \n",
    "        # 載入 embeddings\n",
    "        self.load_saved_embeddings()\n",
    "        \n",
    "    def load_saved_embeddings(self, embeddings_path: str = 'embeddings/embeddings.json'):\n",
    "        \"\"\"載入已保存的embeddings\"\"\"\n",
    "        logger.info(f\"Loading embeddings from {embeddings_path}\")\n",
    "        \n",
    "        with open(embeddings_path, 'r', encoding='utf-8') as f:\n",
    "            self.embeddings_data = json.load(f)\n",
    "        \n",
    "        # 重建FAISS索引\n",
    "        first_embedding = np.array(self.embeddings_data[0]['text_embedding'])\n",
    "        self.index = faiss.IndexFlatL2(len(first_embedding))\n",
    "        \n",
    "        for data in self.embeddings_data:\n",
    "            embedding = np.array(data['text_embedding']).reshape(1, -1)\n",
    "            self.index.add(embedding)\n",
    "            \n",
    "        logger.info(f\"Successfully loaded {len(self.embeddings_data)} embeddings\")\n",
    "    \n",
    "    def get_relevant_docs(self, query: str, k: int = 3) -> List[Dict]:\n",
    "        \"\"\"檢索相關文件\"\"\"\n",
    "        model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "        query_embedding = model.encode(query)\n",
    "        \n",
    "        D, I = self.index.search(query_embedding.reshape(1, -1), k)\n",
    "        \n",
    "        relevant_docs = []\n",
    "        for idx in I[0]:\n",
    "            relevant_docs.append({\n",
    "                'content': self.embeddings_data[idx]['content'],\n",
    "                'metadata': self.embeddings_data[idx]['metadata']\n",
    "            })\n",
    "        \n",
    "        return relevant_docs\n",
    "    \n",
    "    def display_relevant_images(self, relevant_docs: List[Dict]):\n",
    "        \"\"\"顯示相關文件中的圖片\"\"\"\n",
    "        found_images = False\n",
    "        for doc in relevant_docs:\n",
    "            if doc['metadata']['type'] == 'social_post':\n",
    "                content = doc['content']\n",
    "                if isinstance(content, dict) and 'images' in content:\n",
    "                    for img in content['images']:\n",
    "                        img_path = self.image_dir / img\n",
    "                        if img_path.exists():\n",
    "                            display(Image(filename=str(img_path)))\n",
    "                            print(f\"圖片說明: {img}\")\n",
    "                            print(\"相關討論:\")\n",
    "                            print(f\"問題: {content['post']}\")\n",
    "                            print(\"回應:\")\n",
    "                            for resp in content.get('responses', []):\n",
    "                                print(f\"- {resp}\")\n",
    "                            print(\"\\n\")\n",
    "                            found_images = True\n",
    "        \n",
    "        if not found_images:\n",
    "            print(\"未找到相關圖片\")\n",
    "    \n",
    "    def generate_response(self, query: str) -> Tuple[str, List[Dict]]:\n",
    "        \"\"\"生成回應並返回相關文件\"\"\"\n",
    "        logger.info(f\"Processing query: {query}\")\n",
    "        \n",
    "        # 獲取相關文件\n",
    "        relevant_docs = self.get_relevant_docs(query)\n",
    "        \n",
    "        # 準備上下文和圖片\n",
    "        context = \"以下是相關的參考資料：\\n\\n\"\n",
    "        vertex_images = []\n",
    "        \n",
    "        for doc in relevant_docs:\n",
    "            if doc['metadata']['type'] == 'pdf':\n",
    "                context += f\"【醫學文獻】\\n{doc['content']}\\n\\n\"\n",
    "            elif doc['metadata']['type'] == 'social_post':\n",
    "                context += f\"【社群討論】\\n問題：{doc['content']['post']}\\n\"\n",
    "                if doc['content'].get('responses'):\n",
    "                    context += \"回應：\\n\"\n",
    "                    for resp in doc['content']['responses']:\n",
    "                        context += f\"- {resp}\\n\"\n",
    "                \n",
    "                # 處理圖片\n",
    "                if isinstance(doc['content'], dict) and 'images' in doc['content']:\n",
    "                    for img in doc['content']['images']:\n",
    "                        img_path = self.image_dir / img\n",
    "                        if img_path.exists():\n",
    "                            vertex_image = VertexImage.load_from_file(str(img_path))\n",
    "                            if vertex_image:\n",
    "                                vertex_images.append(vertex_image)\n",
    "                                context += f\"[包含圖片: {img}]\\n\"\n",
    "                \n",
    "                if doc['content'].get('link'):\n",
    "                    context += f\"來源：{doc['content']['link']}\\n\"\n",
    "                context += \"\\n\"\n",
    "        \n",
    "        # 構建提示\n",
    "        prompt = f\"\"\"你是一位專業的獸醫師，專精於寵物醫療和行為諮詢，特別在老年寵物照護和認知障礙方面有豐富經驗。\n",
    "請根據提供的參考資料和圖片，針對用戶的問題提供專業的建議。在回答中，請具體描述相關圖片的內容及其對答案的啟發。\n",
    "\n",
    "參考資料：\n",
    "{context}\n",
    "\n",
    "用戶問題：{query}\n",
    "\n",
    "請提供專業且具體的建議，並請：\n",
    "1. 描述相關圖片內容及其啟發\n",
    "2. 引用參考資料來源（醫學文獻/社群討論）\n",
    "3. 如涉及醫療建議，提醒諮詢獸醫\n",
    "\"\"\"\n",
    "\n",
    "        # 準備輸入內容\n",
    "        contents = [prompt]\n",
    "        if vertex_images:\n",
    "            contents.extend(vertex_images)\n",
    "        \n",
    "        # 生成回應\n",
    "        response = self.llm.generate_content(contents)\n",
    "        \n",
    "        return response.text, relevant_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 系統使用示例\n",
    "### 4.1 生成新的 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "INFO:__main__:Processing PDF: salvin2010.pdf\n",
      "INFO:__main__:Extracted 5 paragraphs from PDF\n",
      "INFO:__main__:Processing CSV: post_response.csv\n",
      "INFO:__main__:Added image: image01.jpg\n",
      "INFO:__main__:Added image: image02.jpg\n",
      "INFO:__main__:Processed 3 posts from CSV\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.15it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 56.00it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 57.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 47.11it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.71it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 40.04it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 41.56it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 68.49it/s]\n",
      "INFO:__main__:Saved 8 embedded documents to embeddings/embeddings.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功生成 8 個文件的 embeddings\n"
     ]
    }
   ],
   "source": [
    "# 初始化資料處理器\n",
    "processor = DataProcessor()\n",
    "\n",
    "# 處理資料並生成新的embeddings\n",
    "embedded_docs = processor.process_and_save(\n",
    "    csv_path=\"post_response.csv\",\n",
    "    pdf_path=\"salvin2010.pdf\"\n",
    ")\n",
    "\n",
    "print(f\"成功生成 {len(embedded_docs)} 個文件的 embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 初始化和測試 RAG 系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading embeddings from embeddings/embeddings.json\n",
      "INFO:__main__:Successfully loaded 8 embeddings\n"
     ]
    }
   ],
   "source": [
    "# 初始化 RAG 系統\n",
    "rag_system = MultiModalRAGSystem(\n",
    "    project_id=\"high-tribute-438514-j7\",  # 替換為你的 project ID\n",
    "    location=\"us-central1\",\n",
    "    image_dir=\"image\"\n",
    ")\n",
    "\n",
    "# 測試查詢\n",
    "def test_query(query: str):\n",
    "    print(\"問題：\", query)\n",
    "    print(\"\\n相關圖片：\")\n",
    "    \n",
    "    # 生成回應並獲取相關文件\n",
    "    response, relevant_docs = rag_system.generate_response(query)\n",
    "    \n",
    "    # 顯示相關圖片\n",
    "    rag_system.display_relevant_images(relevant_docs)\n",
    "    \n",
    "    print(\"\\nGemini的回答：\")\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進行多個測試查詢\n",
    "test_queries = [\n",
    "    \"繞圈圈的狗有適合她活動的佈置嗎？\",\n",
    "    \"老狗失智症有什麼症狀？\",\n",
    "    \"晚上狗狗一直叫該怎麼辦？\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    test_query(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 互動式查詢介面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def interactive_query():\n",
    "    while True:\n",
    "        query = input(\"請輸入您的問題 (輸入'quit'結束): \").strip()\n",
    "        \n",
    "        if query.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        test_query(query)\n",
    "        print(\"\\n輸入新的問題或輸入'quit'結束\")\n",
    "\n",
    "# 啟動互動式查詢\n",
    "interactive_query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
