{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Vector DB\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "# Embedding Models\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import torch\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# LLM\n",
    "from vertexai.generative_models import GenerativeModel, Part, Image as VertexImage\n",
    "import vertexai\n",
    "\n",
    "# PDF處理\n",
    "import PyPDF2\n",
    "\n",
    "# 設置日誌\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 檢查並創建必要的目錄\n",
    "Path('chroma_db').mkdir(exist_ok=True)\n",
    "Path('image').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Embedding 處理模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# from IPython.display import display, Image\n",
    "\n",
    "class HybridEmbeddingProcessor:\n",
    "    def __init__(self, \n",
    "                 persist_directory: str = \"chroma_db\",\n",
    "                 image_dir: str = \"image\",\n",
    "                 image_size:tuple=(224,224)):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        # 初始化文本 embedding 模型 - 使用更適合長文本的模型\n",
    "        self.text_model = SentenceTransformer('all-mpnet-base-v2')  # 768維，更好的文本理解\n",
    "        \n",
    "        # 初始化 CLIP 模型 - 專門用於圖片\n",
    "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "        \n",
    "        # 設置 Chroma\n",
    "        self.chroma_client = chromadb.PersistentClient(path=persist_directory)\n",
    "        \n",
    "        # 創建兩個不同的集合，使用不同的 embedding 函數\n",
    "        try:\n",
    "            self.chroma_client.delete_collection(\"text_documents\")\n",
    "            self.chroma_client.delete_collection(\"image_documents\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 文本集合使用 SentenceTransformer\n",
    "        self.text_collection = self.chroma_client.create_collection(\n",
    "            name=\"text_documents\",\n",
    "            embedding_function=embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "                model_name='all-mpnet-base-v2'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        self.image_collection = self.chroma_client.create_collection(\n",
    "            name=\"image_documents\"\n",
    "        )\n",
    "        \n",
    "        logger.info(\"Initialized hybrid embedding system\")\n",
    "    \n",
    "    def process_image(self, image_path: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"處理圖片並生成 embedding，確保 resize\"\"\"\n",
    "        try:\n",
    "            # 使用 PIL 打開圖片\n",
    "            image = PILImage.open(image_path)\n",
    "            \n",
    "            # 將圖片轉換為 RGB 模式（處理 RGBA 圖片）\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "                \n",
    "            # 計算等比例縮放的大小\n",
    "            width, height = image.size\n",
    "            ratio = min(self.image_size[0]/width, self.image_size[1]/height)\n",
    "            new_size = (int(width * ratio), int(height * ratio))\n",
    "            \n",
    "            # 縮放圖片\n",
    "            image = image.resize(new_size, PILImage.Resampling.LANCZOS)\n",
    "            \n",
    "            # 創建新的白色背景圖片\n",
    "            new_image = PILImage.new('RGB', self.image_size, (255, 255, 255))\n",
    "            \n",
    "            # 計算居中位置\n",
    "            x = (self.image_size[0] - new_size[0]) // 2\n",
    "            y = (self.image_size[1] - new_size[1]) // 2\n",
    "            \n",
    "            # 貼上縮放後的圖片\n",
    "            new_image.paste(image, (x, y))\n",
    "            \n",
    "            # 保存處理後的圖片\n",
    "            processed_path = self.image_dir / f\"resized_{Path(image_path).name}\"\n",
    "            new_image.save(processed_path, quality=95)\n",
    "            logger.info(f\"Saved resized image to: {processed_path}\")\n",
    "            \n",
    "            # 生成 embedding\n",
    "            inputs = self.clip_processor(images=new_image, return_tensors=\"pt\")\n",
    "            image_features = self.clip_model.get_image_features(**inputs)\n",
    "            embedding = image_features.detach().numpy()[0]\n",
    "            \n",
    "            return embedding\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing image {image_path}: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def process_text(self, text: str) -> np.ndarray:\n",
    "        \"\"\"使用 SentenceTransformer 處理文本\"\"\"\n",
    "        try:\n",
    "            embedding = self.text_model.encode(text)\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing text: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "    def add_documents(self, \n",
    "                     texts: List[str], \n",
    "                     metadatas: List[Dict],\n",
    "                     images: Optional[List[str]] = None):\n",
    "        \"\"\"添加文件到不同的集合\"\"\"\n",
    "        try:\n",
    "            # 添加文本文件\n",
    "            if texts and metadatas:\n",
    "                self.text_collection.add(\n",
    "                    documents=texts,\n",
    "                    metadatas=metadatas,\n",
    "                    ids=[f\"text_{i}\" for i in range(len(texts))]\n",
    "                )\n",
    "                logger.info(f\"Added {len(texts)} text documents\")\n",
    "            \n",
    "            # 處理並添加圖片\n",
    "            if images:\n",
    "                image_embeddings = []\n",
    "                valid_images = []\n",
    "                valid_metadatas = []\n",
    "                \n",
    "                for i, img_path in enumerate(images):\n",
    "                    embedding = self.process_image(str(self.image_dir / img_path))\n",
    "                    if embedding is not None:\n",
    "                        image_embeddings.append(embedding.tolist())\n",
    "                        valid_images.append(img_path)\n",
    "                        valid_metadatas.append({\n",
    "                            \"type\": \"image\", \n",
    "                            \"path\": img_path,\n",
    "                            \"associated_text\": texts[i] if i < len(texts) else \"\"\n",
    "                        })\n",
    "                \n",
    "                if valid_images:\n",
    "                    self.image_collection.add(\n",
    "                        embeddings=image_embeddings,\n",
    "                        metadatas=valid_metadatas,\n",
    "                        ids=[f\"img_{i}\" for i in range(len(valid_images))]\n",
    "                    )\n",
    "                    logger.info(f\"Added {len(valid_images)} images\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error adding documents: {str(e)}\")\n",
    "            raise\n",
    "    def calculate_image_relevance(self, query: str) -> float:\n",
    "        \"\"\"評估查詢是否需要圖片\"\"\"\n",
    "        # 視覺相關關鍵詞\n",
    "        visual_keywords = {\n",
    "            \"環境\": 1.0,\n",
    "            \"佈置\": 1.0,\n",
    "            \"擺設\": 1.0,\n",
    "            \"空間\": 1.0,\n",
    "            \"設計\": 1.0,\n",
    "            \"擺放\": 1.0,\n",
    "            \"輪椅\": 1.0,\n",
    "            \"器材\": 1.0,\n",
    "            \"設施\": 1.0,\n",
    "            \"游泳池\": 1.0,\n",
    "            \"活動區\": 1.0\n",
    "        }\n",
    "        \n",
    "        # 症狀觀察關鍵詞（較低權重）\n",
    "        symptom_keywords = {\n",
    "            \"姿勢\": 0.5,\n",
    "            \"表現\": 0.5,\n",
    "            \"狀態\": 0.5,\n",
    "            \"行為\": 0.5,\n",
    "            \"動作\": 0.5,\n",
    "            \"症狀\": 0.3,\n",
    "            \"走路\": 0.5,\n",
    "            \"站立\": 0.5,\n",
    "            \"臥躺\": 0.5\n",
    "        }\n",
    "        \n",
    "        # 計算加權分數\n",
    "        score = 0.0\n",
    "        for keyword, weight in {**visual_keywords, **symptom_keywords}.items():\n",
    "            if keyword in query:\n",
    "                score += weight\n",
    "        \n",
    "        # 正規化分數到 0-1\n",
    "        return min(score / 2, 1.0)\n",
    "\n",
    "    def search(self, \n",
    "             query: str, \n",
    "             k: int = 3, \n",
    "             image_threshold: float = 0.3) -> Dict:\n",
    "        \"\"\"改進的混合搜索\"\"\"\n",
    "        try:\n",
    "            # 評估是否需要圖片\n",
    "            image_relevance = self.calculate_image_relevance(query)\n",
    "            logger.info(f\"Image relevance score for query '{query}': {image_relevance}\")\n",
    "            \n",
    "            # 文本搜索\n",
    "            text_results = self.text_collection.query(\n",
    "                query_texts=[query],\n",
    "                n_results=k\n",
    "            )\n",
    "            \n",
    "            # 圖片搜索\n",
    "            image_results = {\n",
    "                \"metadatas\": [],\n",
    "                \"documents\": [],\n",
    "                \"distances\": [],\n",
    "                \"ids\": []\n",
    "            }\n",
    "            \n",
    "            if image_relevance >= image_threshold:\n",
    "                # 使用CLIP的文本編碼器處理查詢\n",
    "                inputs = self.clip_processor(\n",
    "                    text=[query], \n",
    "                    return_tensors=\"pt\", \n",
    "                    padding=True\n",
    "                )\n",
    "                text_features = self.clip_model.get_text_features(**inputs)\n",
    "                query_embedding = text_features.detach().numpy()[0]\n",
    "                query_embedding = query_embedding / np.linalg.norm(query_embedding)\n",
    "                \n",
    "                image_results = self.image_collection.query(\n",
    "                    query_embeddings=[query_embedding.tolist()],\n",
    "                    n_results=k\n",
    "                )\n",
    "            \n",
    "            return {\n",
    "                \"texts\": text_results,\n",
    "                \"images\": image_results,\n",
    "                \"image_relevance\": image_relevance\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Search error: {str(e)}\")\n",
    "            return {\n",
    "                \"texts\": {\n",
    "                    \"ids\": [], \n",
    "                    \"documents\": [], \n",
    "                    \"metadatas\": [], \n",
    "                    \"distances\": []\n",
    "                },\n",
    "                \"images\": {\n",
    "                    \"ids\": [], \n",
    "                    \"documents\": [], \n",
    "                    \"metadatas\": [], \n",
    "                    \"distances\": []\n",
    "                },\n",
    "                \"image_relevance\": 0.0\n",
    "            }\n",
    "\n",
    "    \n",
    "    def display_search_results(self, query: str, k: int = 3, display_size: tuple = (400, 400)):\n",
    "        \"\"\"顯示搜索結果，控制顯示大小\"\"\"\n",
    "        results = self.search(query, k)\n",
    "        \n",
    "        print(f\"Query: {query}\\n\")\n",
    "        \n",
    "        # 顯示圖片結果\n",
    "        if results[\"image_relevance\"] >= 0.3 and results[\"images\"][\"metadatas\"]:\n",
    "            print(\"Related Images:\")\n",
    "            try:\n",
    "                \n",
    "                for i, meta in enumerate(results[\"images\"][\"metadatas\"][0], 1):\n",
    "                    print(f\"\\nImage {i}:\")\n",
    "                    \n",
    "                    # 讀取原始圖片\n",
    "                    img_path = self.image_dir / meta['path']\n",
    "                    if img_path.exists():\n",
    "                        # 重新調整大小用於顯示\n",
    "                        img = PILImage.open(img_path)\n",
    "                        \n",
    "                        # 轉換為 RGB 模式\n",
    "                        if img.mode != 'RGB':\n",
    "                            img = img.convert('RGB')\n",
    "                        \n",
    "                        # 計算等比例縮放\n",
    "                        width, height = img.size\n",
    "                        ratio = min(display_size[0]/width, display_size[1]/height)\n",
    "                        new_size = (int(width * ratio), int(height * ratio))\n",
    "                        \n",
    "                        # 縮放圖片\n",
    "                        img = img.resize(new_size, PILImage.Resampling.LANCZOS)\n",
    "                        \n",
    "                        # 創建新的背景\n",
    "                        display_img = PILImage.new('RGB', display_size, (255, 255, 255))\n",
    "                        x = (display_size[0] - new_size[0]) // 2\n",
    "                        y = (display_size[1] - new_size[1]) // 2\n",
    "                        display_img.paste(img, (x, y))\n",
    "                        \n",
    "                        # 保存臨時檔案用於顯示\n",
    "                        temp_path = self.image_dir / f\"temp_display_{meta['path']}\"\n",
    "                        display_img.save(temp_path)\n",
    "                        \n",
    "                        # 顯示圖片\n",
    "                        display.display(display.Image(filename=str(temp_path)))\n",
    "                        \n",
    "                        # 清理臨時檔案\n",
    "                        temp_path.unlink()\n",
    "                        \n",
    "                        if 'associated_text' in meta:\n",
    "                            print(f\"Context: {meta['associated_text'][:200]}...\")\n",
    "                            \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error displaying images: {str(e)}\")\n",
    "                print(\"Error displaying images\")\n",
    "        else:\n",
    "            if results[\"image_relevance\"] < 0.3:\n",
    "                print(\"No images needed for this query\")\n",
    "            else:\n",
    "                print(\"No relevant images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 資料處理模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, embedding_processor: EmbeddingProcessor):\n",
    "        self.embedding_processor = embedding_processor\n",
    "        \n",
    "    def process_csv_with_images(self, csv_path: str) -> Tuple[List[str], List[Dict], List[str]]:\n",
    "        \"\"\"處理 CSV 並提取圖片，確保 metadata 值都是基本類型\"\"\"\n",
    "        logger.info(f\"Processing CSV: {csv_path}\")\n",
    "        texts = []\n",
    "        metadatas = []\n",
    "        images = []\n",
    "        \n",
    "        df = pd.read_csv(csv_path)\n",
    "        current_post = None\n",
    "        current_responses = []\n",
    "        current_images = []\n",
    "        current_metadata = None\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            # 開始新的貼文\n",
    "            if pd.notna(row['post']):\n",
    "                if current_post is not None:\n",
    "                    # 保存前一個貼文\n",
    "                    text = f\"{current_post} {' '.join(current_responses)}\"\n",
    "                    texts.append(text)\n",
    "                    if current_images:\n",
    "                        current_metadata[\"images\"] = \",\".join(current_images)\n",
    "                        images.extend(current_images)\n",
    "                    # 將回應列表轉換為字符串，使用 | 作為分隔符\n",
    "                    current_metadata[\"responses\"] = \"|\".join(current_responses)\n",
    "                    metadatas.append(current_metadata)\n",
    "                \n",
    "                # 初始化新貼文\n",
    "                current_post = row['post']\n",
    "                current_responses = []\n",
    "                current_images = []\n",
    "                current_metadata = {\n",
    "                    \"type\": \"social_post\",\n",
    "                    \"source\": \"facebook\",\n",
    "                    \"is_post\": True,\n",
    "                    \"original_post\": current_post\n",
    "                }\n",
    "                \n",
    "                # 添加連結（如果有）\n",
    "                if pd.notna(row['link']):\n",
    "                    current_metadata[\"link\"] = row['link']\n",
    "            \n",
    "            # 添加回覆\n",
    "            if pd.notna(row['responses']):\n",
    "                current_responses.append(row['responses'])\n",
    "                \n",
    "            # 處理圖片\n",
    "            if pd.notna(row.get('images')):\n",
    "                img_path = row['images']\n",
    "                current_images.append(img_path)\n",
    "                logger.info(f\"Found image: {img_path} for current post\")\n",
    "        \n",
    "        # 保存最後一個貼文\n",
    "        if current_post is not None:\n",
    "            text = f\"{current_post} {' '.join(current_responses)}\"\n",
    "            texts.append(text)\n",
    "            if current_images:\n",
    "                current_metadata[\"images\"] = \",\".join(current_images)\n",
    "                images.extend(current_images)\n",
    "            # 將回應列表轉換為字符串\n",
    "            current_metadata[\"responses\"] = \"|\".join(current_responses)\n",
    "            metadatas.append(current_metadata)\n",
    "        \n",
    "        # 顯示處理結果的詳細資訊\n",
    "        for i, (text, meta) in enumerate(zip(texts, metadatas)):\n",
    "            logger.info(f\"\\nPost {i+1}:\")\n",
    "            logger.info(f\"Content: {text[:100]}...\")\n",
    "            logger.info(f\"Images: {meta.get('images', 'No images')}\")\n",
    "            # 使用 split('|') 代替 split('\\n')\n",
    "            logger.info(f\"Responses: {len(meta.get('responses', '').split('|'))} replies\")\n",
    "            logger.info(f\"Link: {meta.get('link', 'No link')}\")\n",
    "        \n",
    "        return texts, metadatas, images\n",
    "\n",
    "    def process_pdf(self, pdf_path: str) -> List[Dict]:\n",
    "        \"\"\"處理 PDF 文件，確保 metadata 值都是基本類型\"\"\"\n",
    "        logger.info(f\"Processing PDF: {pdf_path}\")\n",
    "        documents = []\n",
    "        \n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    text = page.extract_text()\n",
    "                    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "                    \n",
    "                    for para in paragraphs:\n",
    "                        documents.append({\n",
    "                            'content': para,\n",
    "                            'metadata': {\n",
    "                                'source': pdf_path,\n",
    "                                'page': str(page_num + 1),  # 轉換為字符串\n",
    "                                'type': 'pdf',\n",
    "                                'content_length': str(len(para))  # 添加額外信息，也確保是字符串\n",
    "                            }\n",
    "                        })\n",
    "            \n",
    "            logger.info(f\"Extracted {len(documents)} paragraphs from PDF\")\n",
    "            return documents\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF {pdf_path}: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "    def process_all(self, csv_path: str, pdf_path: str):\n",
    "        \"\"\"處理所有資料，確保所有 metadata 正確\"\"\"\n",
    "        logger.info(\"Starting to process all documents...\")\n",
    "        \n",
    "        try:\n",
    "            # 處理 CSV 和圖片\n",
    "            texts, metadatas, images = self.process_csv_with_images(csv_path)\n",
    "            logger.info(f\"\\nFound {len(images)} images:\")\n",
    "            for img in images:\n",
    "                logger.info(f\"- {img}\")\n",
    "            \n",
    "            # 檢查圖片文件是否存在\n",
    "            image_dir = Path(\"image\")\n",
    "            valid_images = []\n",
    "            for img in images:\n",
    "                img_path = image_dir / img\n",
    "                if img_path.exists():\n",
    "                    logger.info(f\"Image file exists: {img_path}\")\n",
    "                    valid_images.append(img)\n",
    "                else:\n",
    "                    logger.error(f\"Image file not found: {img_path}\")\n",
    "            \n",
    "            # 處理 PDF\n",
    "            pdf_docs = self.process_pdf(pdf_path)\n",
    "            texts.extend([doc['content'] for doc in pdf_docs])\n",
    "            metadatas.extend([doc['metadata'] for doc in pdf_docs])\n",
    "            \n",
    "            logger.info(f\"\\nProcessing summary:\")\n",
    "            logger.info(f\"- Total texts: {len(texts)}\")\n",
    "            logger.info(f\"- Total valid images: {len(valid_images)}\")\n",
    "            \n",
    "            # 最終檢查確保所有 metadata 值都是基本類型\n",
    "            for meta in metadatas:\n",
    "                for key, value in list(meta.items()):\n",
    "                    if isinstance(value, (list, dict)):\n",
    "                        meta[key] = str(value)\n",
    "            \n",
    "            # 添加到 Chroma\n",
    "            self.embedding_processor.add_documents(\n",
    "                texts=texts,\n",
    "                metadatas=metadatas,\n",
    "                images=valid_images\n",
    "            )\n",
    "            \n",
    "            logger.info(f\"Successfully processed all documents\")\n",
    "            return len(texts), len(valid_images)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing documents: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. QA系統模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QASystem:\n",
    "    def __init__(self,\n",
    "                 embedding_processor: HybridEmbeddingProcessor,\n",
    "                 project_id: str,\n",
    "                 location: str = \"us-central1\"):\n",
    "        self.embedding_processor = embedding_processor\n",
    "        self.init_llm(project_id, location)\n",
    "        \n",
    "    def init_llm(self, project_id: str, location: str):\n",
    "        \"\"\"初始化 Gemini\"\"\"\n",
    "        vertexai.init(project=project_id, location=location)\n",
    "        self.llm = GenerativeModel('gemini-1.0-pro-vision-001')\n",
    "    \n",
    "    def generate_response(self, query: str) -> Tuple[str, List[VertexImage]]:\n",
    "        \"\"\"改進的回應生成\"\"\"\n",
    "        # 搜索相關內容\n",
    "        search_results = self.embedding_processor.search(query)\n",
    "        image_relevance = search_results[\"image_relevance\"]\n",
    "        \n",
    "        # 根據不同的情況使用不同的提示模板\n",
    "        if image_relevance >= 0.3:\n",
    "            prompt = f\"\"\"你是一位專業的獸醫師，專精於寵物醫療和行為諮詢。\n",
    "這個問題與環境設置或視覺觀察相關，請特別注意參考提供的圖片資訊。\n",
    "\n",
    "參考資料：\n",
    "{self.format_context(search_results)}\n",
    "\n",
    "用戶問題：{query}\n",
    "\n",
    "請提供專業且具體的建議，並：\n",
    "1. 詳細描述相關圖片內容及其啟發\n",
    "2. 解釋如何將圖片中的方案應用到實際情況\n",
    "3. 引用參考資料來源（醫學文獻/社群討論）\n",
    "4. 如涉及醫療建議，提醒諮詢獸醫\"\"\"\n",
    "        else:\n",
    "            prompt = f\"\"\"你是一位專業的獸醫師，專精於寵物醫療和行為諮詢。\n",
    "這個問題主要與醫療或行為建議相關。\n",
    "\n",
    "參考資料：\n",
    "{self.format_context(search_results)}\n",
    "\n",
    "用戶問題：{query}\n",
    "\n",
    "請提供專業且具體的建議，並：\n",
    "1. 根據醫學文獻提供專業解釋\n",
    "2. 引用社群經驗作為輔助參考\n",
    "3. 如有必要，提供具體的照護建議\n",
    "4. 提醒需要就醫評估的情況\"\"\"\n",
    "\n",
    "        # 準備內容\n",
    "        contents = [prompt]\n",
    "        vertex_images = []\n",
    "        \n",
    "        # 只在相關時添加圖片\n",
    "        if image_relevance >= 0.3 and search_results[\"images\"]:\n",
    "            for metadata in search_results[\"images\"][\"metadatas\"][0]:\n",
    "                img_path = self.embedding_processor.image_dir / metadata[\"path\"]\n",
    "                if img_path.exists():\n",
    "                    image = VertexImage.load_from_file(str(img_path))\n",
    "                    contents.append(image)\n",
    "                    vertex_images.append(image)\n",
    "        \n",
    "        # 生成回應\n",
    "        response = self.llm.generate_content(contents)\n",
    "        return response.text, vertex_images\n",
    "\n",
    "    def format_context(self, search_results: Dict) -> str:\n",
    "        \"\"\"格式化上下文\"\"\"\n",
    "        context = \"\"\n",
    "        \n",
    "        # 添加文本結果\n",
    "        for doc, meta in zip(\n",
    "            search_results[\"texts\"][\"documents\"][0],\n",
    "            search_results[\"texts\"][\"metadatas\"][0]\n",
    "        ):\n",
    "            if meta[\"type\"] == \"pdf\":\n",
    "                context += f\"【醫學文獻】\\n{doc}\\n\\n\"\n",
    "            else:\n",
    "                context += f\"【社群討論】\\n{doc}\\n\"\n",
    "                if meta.get(\"link\"):\n",
    "                    context += f\"來源：{meta['link']}\\n\\n\"\n",
    "        \n",
    "        # 只在相關時添加圖片資訊\n",
    "        if search_results[\"image_relevance\"] >= 0.3:\n",
    "            context += \"\\n【相關圖片】\\n\"\n",
    "            for meta in search_results[\"images\"].get(\"metadatas\", [{}])[0]:\n",
    "                context += f\"- {meta['path']}\\n\"\n",
    "        \n",
    "        return context\n",
    "\n",
    "    def display_response(self, query: str):\n",
    "        \"\"\"顯示回應\"\"\"\n",
    "        response_text, images = self.generate_response(query)\n",
    "        \n",
    "        print(\"問題：\", query)\n",
    "        if images:\n",
    "            print(\"\\n相關圖片：\")\n",
    "            for img in images:\n",
    "                display(img)\n",
    "        \n",
    "        print(\"\\nGemini的回答：\")\n",
    "        print(response_text)\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 系統初始化和資料處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "INFO:__main__:Initialized hybrid embedding system\n",
      "INFO:__main__:Starting to process all documents...\n",
      "INFO:__main__:Processing CSV: post_response.csv\n",
      "INFO:__main__:Found image: image01.jpg for current post\n",
      "INFO:__main__:Found image: image02.jpg for current post\n",
      "INFO:__main__:Found image: image03.jpg for current post\n",
      "INFO:__main__:\n",
      "Post 1:\n",
      "INFO:__main__:Content: 失智的狗狗，如果晚上四處走，不懂自己睡，是否買輪椅給牠晚上用，讓牠累就直接睡比較好？但我看到長期用手腳的位置會紅呢，應該怎樣比較好？（現在都是抱牠入睡，但凌晨牠自己起身我也不知道呢）請指教。 輪椅不能...\n",
      "INFO:__main__:Images: image01.jpg,image02.jpg,image03.jpg\n",
      "INFO:__main__:Responses: 7 replies\n",
      "INFO:__main__:Link: https://www.facebook.com/share/p/qFf55T4BgHJs6TzY/\n",
      "INFO:__main__:\n",
      "Post 2:\n",
      "INFO:__main__:Content: 吃老狗失智夜晚狂叫，有何妙方？ 請醫生開立輕微鎮靜的藥，不要覺得捨不得，狗狗一直叫沒有休息也是不行的，主人更應該得到好的睡眠才能照顧好寶貝 白天盡量多散步、或是在家裡陪他活動，請醫生開保健品、嚴重的時...\n",
      "INFO:__main__:Images: No images\n",
      "INFO:__main__:Responses: 9 replies\n",
      "INFO:__main__:Link: https://www.facebook.com/groups/403191506497801/permalink/2631558230327773/?rdid=HqDuRASCUk53jABS&share_url=https%3A%2F%2Fwww.facebook.com%2Fshare%2Fp%2FidyouqqRo1EWrH3H%2F\n",
      "INFO:__main__:\n",
      "Post 3:\n",
      "INFO:__main__:Content: 關於犬失智有問題想請益\n",
      "上禮拜開始發現家中小狗（11歲）開始對於指令失去反應，聯想到前陣子他開始偶爾會躲在角落，有時候好像也會不認得我姊姊，懷疑他開始有失智的情形。\n",
      "1.已有預約台大神經科醫師診察，但...\n",
      "INFO:__main__:Images: No images\n",
      "INFO:__main__:Responses: 5 replies\n",
      "INFO:__main__:Link: https://www.facebook.com/share/p/6DkLRFqSQQBN7G3M/\n",
      "INFO:__main__:\n",
      "Found 3 images:\n",
      "INFO:__main__:- image01.jpg\n",
      "INFO:__main__:- image02.jpg\n",
      "INFO:__main__:- image03.jpg\n",
      "INFO:__main__:Image file exists: image/image01.jpg\n",
      "INFO:__main__:Image file exists: image/image02.jpg\n",
      "INFO:__main__:Image file exists: image/image03.jpg\n",
      "INFO:__main__:Processing PDF: salvin2010.pdf\n",
      "INFO:__main__:Extracted 5 paragraphs from PDF\n",
      "INFO:__main__:\n",
      "Processing summary:\n",
      "INFO:__main__:- Total texts: 8\n",
      "INFO:__main__:- Total valid images: 3\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n",
      "INFO:__main__:Added 8 text documents\n",
      "INFO:__main__:Saved resized image to: image/resized_image01.jpg\n",
      "INFO:__main__:Saved resized image to: image/resized_image02.jpg\n",
      "INFO:__main__:Saved resized image to: image/resized_image03.jpg\n",
      "INFO:__main__:Added 3 images\n",
      "INFO:__main__:Successfully processed all documents\n"
     ]
    }
   ],
   "source": [
    "embedding_processor = HybridEmbeddingProcessor(\n",
    "    image_size=(224, 224)\n",
    ")\n",
    "data_processor = DataProcessor(embedding_processor)\n",
    "\n",
    "# 處理資料\n",
    "num_texts, num_images = data_processor.process_all(\n",
    "    csv_path=\"post_response.csv\",\n",
    "    pdf_path=\"salvin2010.pdf\"\n",
    ")\n",
    "\n",
    "# 測試搜索\n",
    "# embedding_processor.display_search_results(\n",
    "#     \"狗狗失智的症狀有哪些？\",\n",
    "#     k=3\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 系統測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化 QA 系統\n",
    "qa_system = QASystem(\n",
    "    embedding_processor=embedding_processor,\n",
    "    project_id=\"high-tribute-438514-j7\",  # 替換為你的 project ID\n",
    "    location=\"us-central1\"\n",
    ")\n",
    "\n",
    "# 測試查詢\n",
    "test_queries = [\n",
    "    \"繞圈圈的狗有適合她活動的佈置嗎？\"\n",
    "    # ,\n",
    "    # \"老狗失智症有什麼症狀？\",\n",
    "    # \"晚上狗狗一直叫該怎麼辦？\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    qa_system.display_response(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 互動式查詢介面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def interactive_query():\n",
    "    while True:\n",
    "        query = input(\"請輸入您的問題 (輸入'quit'結束): \").strip()\n",
    "        \n",
    "        if query.lower() == 'quit':\n",
    "            break\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        qa_system.display_response(query)\n",
    "        print(\"\\n輸入新的問題或輸入'quit'結束\")\n",
    "\n",
    "# 啟動互動式查詢\n",
    "interactive_query()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
