{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 轉py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook rag_system_llama.ipynb to script\n",
      "[NbConvertApp] Writing 56052 bytes to rag_system_llama.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script rag_system_llama.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zirong/miniforge3/envs/llm/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Display and Image handling\n",
    "from IPython.display import display\n",
    "from PIL import Image as PILImage  # 使用 PILImage 作为 PIL.Image 的别名\n",
    "from IPython.display import Image as IPyImage  # 使用 IPyImage 作为 IPython 的 Image\n",
    "\n",
    "# Vector DB\n",
    "import chromadb\n",
    "\n",
    "\n",
    "# LLM\n",
    "import ollama\n",
    "\n",
    "# PDF处理\n",
    "import PyPDF2\n",
    "\n",
    "# 设置日志\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# 检查并创建必要的目录\n",
    "Path('chroma_db').mkdir(exist_ok=True)\n",
    "Path('image').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.19 | packaged by conda-forge | (main, Mar 20 2024, 12:55:20) \n",
      "[Clang 16.0.6 ]\n",
      "PyTorch version: 2.6.0\n",
      "Transformers version: 4.51.3\n",
      "Accelerate version: 1.6.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import transformers\n",
    "import accelerate\n",
    "# print(f\"Python version: {sys.version}\")\n",
    "# print(f\"PyTorch version: {torch.__version__}\")\n",
    "# print(f\"Transformers version: {transformers.__version__}\")\n",
    "# print(f\"Accelerate version: {accelerate.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 放在檔案最上方 (import 之後)\n",
    "TYPE_MAP = {\n",
    "    \"acupoint\"    : [\"針灸\", \"acupuncture\"],\n",
    "    \"herb\"        : [\"herbology\", \"herbal\", \"方劑\"],\n",
    "    \"ccd\"         : [\"ccd\", \"認知\", \"cognition\"],\n",
    "    \"social\"      : [],                   # csv 直接指定\n",
    "    \"professional\": [],\n",
    "    \"image\":[]                                       # 其他未分類\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### voice to text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper /Users/zirong/Desktop/test.mp4 --language Chinese --model tiny\n",
    "import whisper\n",
    "def transcribe_file(file_path, model_size=\"base\"):\n",
    "    model = whisper.load_model(model_size)\n",
    "    result = model.transcribe(file_path)\n",
    "    return result[\"text\"]\n",
    "\n",
    "# def main():\n",
    "#     audio_file = \"no_upload/test_mp3/01.mp3\"  # 修改為你的音檔路徑\n",
    "#     transcription = transcribe_file(audio_file)\n",
    "#     print(\"Transcription:\", transcription)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 圖片處理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union  # 添加 Union 导入\n",
    "from pathlib import Path\n",
    "\n",
    "class ImageProcessor:\n",
    "    def __init__(self, image_dir: str = \"image\"):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.image_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "    def process_and_save(\n",
    "        self,\n",
    "        image_path: Union[str, Path],  # 使用 Union 替代 |\n",
    "        target_size: Tuple[int, int],\n",
    "        prefix: str = \"resized_\",\n",
    "        quality: int = 95\n",
    "    ) -> Optional[Path]:\n",
    "        \"\"\"统一的图片处理方法，处理并保存图片\"\"\"\n",
    "        try:\n",
    "            # 确保 image_path 是 Path 对象\n",
    "            image_path = Path(image_path)\n",
    "            if not str(image_path).startswith(str(self.image_dir)):\n",
    "                image_path = self.image_dir / image_path\n",
    "                \n",
    "            # 检查图片是否存在\n",
    "            if not image_path.exists():\n",
    "                logger.error(f\"Image not found: {image_path}\")\n",
    "                return None\n",
    "                \n",
    "            # 读取并处理图片\n",
    "            image = PILImage.open(image_path)\n",
    "            \n",
    "            # 转换为 RGB 模式\n",
    "            if image.mode != 'RGB':\n",
    "                image = image.convert('RGB')\n",
    "                \n",
    "            # 计算等比例缩放的大小\n",
    "            width, height = image.size\n",
    "            ratio = min(target_size[0]/width, target_size[1]/height)\n",
    "            new_size = (int(width * ratio), int(height * ratio))\n",
    "            \n",
    "            # 缩放图片\n",
    "            image = image.resize(new_size, PILImage.Resampling.LANCZOS)\n",
    "            \n",
    "            # 创建新的白色背景图片\n",
    "            new_image = PILImage.new('RGB', target_size, (255, 255, 255))\n",
    "            \n",
    "            # 计算居中位置\n",
    "            x = (target_size[0] - new_size[0]) // 2\n",
    "            y = (target_size[1] - new_size[1]) // 2\n",
    "            \n",
    "            # 贴上缩放后的图片\n",
    "            new_image.paste(image, (x, y))\n",
    "            \n",
    "            # 生成输出路径\n",
    "            output_path = self.image_dir / f\"{image_path.name}\" #output_path = self.image_dir / f\"{prefix}{image_path.name}\"\n",
    "            # 保存处理后的图片\n",
    "            new_image.save(output_path, quality=quality)\n",
    "            logger.info(f\"Saved processed image to: {output_path}\")\n",
    "            \n",
    "            return output_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing image {image_path}: {str(e)}\")\n",
    "            return None\n",
    "            \n",
    "    def load_for_display(self, \n",
    "                        image_path: Union[str, Path],  # 使用 Union 替代 |\n",
    "                        display_size: Tuple[int, int]) -> Optional[PILImage.Image]:\n",
    "        \"\"\"载入图片用于显示\"\"\"\n",
    "        try:\n",
    "            processed_path = self.process_and_save(image_path, display_size, prefix=\"display_\")\n",
    "            if processed_path:\n",
    "                return PILImage.open(processed_path)\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image for display {image_path}: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding 處理模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import torch\n",
    "import sentencepiece as spm \n",
    "\n",
    "class EmbeddingProcessor:\n",
    "\n",
    "    MAX_TOKEN = 56          # 56 + BOS + EOS = 58 < 64\n",
    "    OVERLAP   = 16\n",
    "    DEFAULT_COLLECTION = \"ccd_docs_siglip\"\n",
    "\n",
    "    # 初始化 embedding processor\n",
    "    def __init__(self, \n",
    "                persist_directory: str = \"chroma_db\",\n",
    "                image_dir: str = \"image\",\n",
    "                image_size: tuple = (224, 224),\n",
    "                collection_name:str = DEFAULT_COLLECTION,\n",
    "                reset: bool = False \n",
    "                ):\n",
    "        \"\"\"\n",
    "        初始化: 建立clip_collection,使用CLIP(or OpenCLIP)做embedding\n",
    "        \"\"\"\n",
    "        # ---------- 路徑 & 基本設定 ----------\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.image_size = image_size\n",
    "        self.collection_name = collection_name\n",
    "        self.image_processor = ImageProcessor(image_dir)\n",
    "\n",
    "        # ---------- 1) 建立 Chroma client ----------\n",
    "        logger.info(f\"Initializing Chroma with directory: {persist_directory}\")\n",
    "        self.chroma_client = chromadb.PersistentClient(path=persist_directory)\n",
    "\n",
    "        # ---------- 2) reset (= 刪掉舊庫) ----------\n",
    "        if reset:\n",
    "            try:\n",
    "                self.chroma_client.delete_collection(self.collection_name)\n",
    "                logger.info(f\"Deleted collection: {self.collection_name}\")\n",
    "            except (chromadb.errors.NotFoundError, ValueError):\n",
    "                logger.info(\"No old collection to delete\")\n",
    "\n",
    "        \n",
    "        # ---------- 3) 初始化 SigLIP ----------\n",
    "        SIGLIP_NAME = \"google/siglip-base-patch16-224\"\n",
    "        self.processor = AutoProcessor.from_pretrained(SIGLIP_NAME)\n",
    "        self.siglip    = AutoModel.from_pretrained(SIGLIP_NAME)\n",
    "\n",
    "        # 取輸出向量長度 (base = 768)\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.zeros((1, 3, 224, 224))\n",
    "            self.clip_dim = self.siglip.get_image_features(dummy).shape[1]\n",
    "\n",
    "        # ---------- 4) 取得或建立 collection ----------\n",
    "        self.clip_collection = self.chroma_client.get_or_create_collection(\n",
    "            name     = self.collection_name,\n",
    "            metadata = {\"dimension\": self.clip_dim}\n",
    "        )\n",
    "        logger.info(\n",
    "            f\"Using collection '{self.collection_name}' \"\n",
    "            f\"(dimension={self.clip_dim}, reset={reset})\"\n",
    "        )\n",
    "\n",
    "    def to_2d(self,x):\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            x = x.detach().cpu().numpy()\n",
    "        elif isinstance(x, list):\n",
    "            x = np.asarray(x, dtype=np.float32)\n",
    "        if x.ndim == 1:        # (512,) → (1,512)\n",
    "            x = x[None, :]\n",
    "        elif x.ndim != 2:\n",
    "            raise ValueError(f\"embedding ndim should be 1 or 2, got {x.shape}\")\n",
    "        return x.tolist()      # List[List[float]]\n",
    "\n",
    "    def chunk_text_by_token(\n",
    "            self,\n",
    "            text: str,\n",
    "            max_tokens: Optional[int] = None,\n",
    "            overlap: Optional[int] = None\n",
    "        ) -> List[str]:\n",
    "        CH_SENT_SPLIT = re.compile(r'([。！？；\\n])')\n",
    "        \"\"\"句號優先斷句；任何子句最終都 ≤ 56 token\"\"\"\n",
    "        max_tokens = max_tokens or self.MAX_TOKEN      # 56\n",
    "        overlap    = overlap    or self.OVERLAP        # 16\n",
    "\n",
    "        # --- 1) 以中文標點切成子句 ---\n",
    "        sentences, buf, parts = [], \"\", CH_SENT_SPLIT.split(text)\n",
    "        for frag in parts:\n",
    "            if CH_SENT_SPLIT.match(frag):\n",
    "                buf += frag          # 把標點加回來\n",
    "                sentences.append(buf.strip())\n",
    "                buf = \"\"\n",
    "            else:\n",
    "                buf += frag\n",
    "        if buf: sentences.append(buf.strip())\n",
    "\n",
    "        # --- 2) 任何 >56 token 的句子再滑窗切 ---\n",
    "        chunks = []\n",
    "        for s in sentences:\n",
    "            ids = self.processor.tokenizer(s).input_ids\n",
    "            if len(ids) <= max_tokens:\n",
    "                chunks.append(s)\n",
    "            else:\n",
    "                step = max_tokens - overlap\n",
    "                for i in range(0, len(ids), step):\n",
    "                    seg_ids = ids[i:i + max_tokens]\n",
    "                    seg = self.processor.tokenizer.decode(seg_ids,\n",
    "                                                        skip_special_tokens=True)\n",
    "                    chunks.append(seg)\n",
    "        return chunks\n",
    "\n",
    "\n",
    "    def encode_text_to_vec(self, text: str) -> Optional[np.ndarray]:\n",
    "        \"\"\"\n",
    "        用 CLIP 的 text encoder 將文字轉為512維向量\n",
    "        \"\"\"\n",
    "        try:\n",
    "            chunks = self.chunk_text_by_token(text)\n",
    "            if not chunks:\n",
    "                logger.error(\"No valid chunks generated for the text.\")\n",
    "                return None\n",
    "            all_vecs = []\n",
    "            for ch in chunks:\n",
    "                inp = self.processor(text=[ch], return_tensors=\"pt\").to(self.siglip.device)\n",
    "                with torch.no_grad():\n",
    "                    vec = self.siglip.get_text_features(**inp)\n",
    "                all_vecs.append(vec)\n",
    "            # 這裡可取平均或直接回傳多條向量\n",
    "            embs = torch.stack(all_vecs).mean(dim=0)\n",
    "            emb = embs / embs.norm(dim=-1, keepdim=True)\n",
    "            return emb.squeeze(0).cpu().tolist()   \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in encode_text_to_vec: {e}\")\n",
    "            return None\n",
    "        \n",
    "    def add_qa_pairs(self,\n",
    "                questions: List[str],\n",
    "                answers: List[str],\n",
    "                question_metadatas: List[Dict],\n",
    "                answer_metadatas: List[Dict],\n",
    "                images: Optional[List[str]] = None):\n",
    "        \"\"\"添加问答对到不同的集合\"\"\"\n",
    "        try:\n",
    "            # 添加问题\n",
    "            if questions and question_metadatas:\n",
    "                logger.info(f\"Adding {len(questions)} questions\")\n",
    "                self.question_collection.add(\n",
    "                    documents=questions,\n",
    "                    metadatas=question_metadatas,\n",
    "                    ids=[f\"q_{i}\" for i in range(len(questions))]\n",
    "                )\n",
    "            \n",
    "            # 添加回答\n",
    "            if answers and answer_metadatas:\n",
    "                logger.info(f\"Adding {len(answers)} answers\")\n",
    "                self.answer_collection.add(\n",
    "                    documents=answers,\n",
    "                    metadatas=answer_metadatas,\n",
    "                    ids=[f\"a_{i}\" for i in range(len(answers))]\n",
    "                )\n",
    "            \n",
    "            # 处理图片\n",
    "            if images:\n",
    "                logger.info(f\"Processing {len(images)} images\")\n",
    "                all_ids=[]\n",
    "                all_embeddings=[]\n",
    "                all_metadatas = []\n",
    "\n",
    "                \n",
    "                for i, (img_path,question_text) in enumerate(zip(images, questions)):\n",
    "                    img_emb = self.process_image(str(self.image_dir / img_path))\n",
    "                    txt_emb = self.encode_text_to_vec(question_text)\n",
    "\n",
    "                    if img_emb is not None:\n",
    "                        all_embeddings.append(img_emb.tolist())\n",
    "                        all_metadatas.append({\n",
    "                            \"type\": \"image\", \n",
    "                            \"path\": img_path,\n",
    "                            \"associated_question\": question_text\n",
    "                        })\n",
    "                        all_ids.append(f\"img_{i}\")\n",
    "                    if txt_emb is not None:\n",
    "                        all_embeddings.append(txt_emb.tolist())  \n",
    "                        all_metadatas.append({\n",
    "                            \"type\": \"clip_text\", \n",
    "                            \"text\": question_text,\n",
    "                            \"related_image\": img_path\n",
    "                        })\n",
    "                        all_ids.append(f\"txt_{i}\")\n",
    "\n",
    "                if len(all_embeddings)>0:\n",
    "                    logger.info(f\"Adding {len(all_embeddings)} total embeddings to collection\")\n",
    "                    self.image_collection.add(\n",
    "                        embeddings=all_embeddings,\n",
    "                        metadatas=all_metadatas,\n",
    "                        ids=all_ids\n",
    "                    )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error adding QA pairs: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def encode_image_to_vec(self, image_path: str) -> Optional[np.ndarray]:\n",
    "            \"\"\"\n",
    "            用 CLIP image encoder 將圖片轉為512維向量\n",
    "            \"\"\"\n",
    "            try:\n",
    "                # 先做基礎處理,縮放或另存\n",
    "                processed_path = self.image_processor.process_and_save(\n",
    "                    image_path, self.image_size\n",
    "                )\n",
    "                if not processed_path:\n",
    "                    return None\n",
    "\n",
    "                image = PILImage.open(processed_path)\n",
    "                inputs = self.processor(images=[image], return_tensors=\"pt\").to(self.siglip.device)\n",
    "                with torch.no_grad():\n",
    "                    embs = self.siglip.get_image_features(**inputs)\n",
    "                return (embs / embs.norm(dim=-1, keepdim=True)).cpu().numpy()\n",
    "            except Exception as e:\n",
    "                print(f\"Error in encode_image_to_vec: {str(e)}\")\n",
    "                return None\n",
    "\n",
    "    def add_vectors(\n",
    "        self,\n",
    "        texts: Optional[List[str]] = None,\n",
    "        metadatas: Optional[List[Dict]] = None,\n",
    "        images: Optional[List[str]] = None,\n",
    "        ):\n",
    "        \"\"\"\n",
    "        統一把文字 / 圖片寫進 clip_collection\n",
    "        \"\"\"\n",
    "        texts     = texts or []\n",
    "        images    = images or []\n",
    "        metadatas = metadatas or []\n",
    "\n",
    "        all_embs, all_metas, docs, all_ids = [], [], [], []\n",
    "        idx = 0\n",
    "\n",
    "        # -------------------- 文字 --------------------\n",
    "        for i, txt in enumerate(texts):\n",
    "            emb = self.encode_text_to_vec(txt)\n",
    "            if emb is None:\n",
    "                continue\n",
    "\n",
    "            # ① 取 metadata 且保證是 dict\n",
    "            src_meta = metadatas[i] if i < len(metadatas) else {}\n",
    "            if not isinstance(src_meta, dict):\n",
    "                src_meta = {\"note\": str(src_meta)}\n",
    "\n",
    "            # ② domain → type 映射（只做一次）\n",
    "            domain = src_meta.pop(\"domain\", \"\").lower()\n",
    "            if domain in {\"針灸學\", \"acupuncture\"}:\n",
    "                src_meta[\"type\"] = \"acupoint\"\n",
    "            elif domain in {\"中醫方劑\", \"herb\"}:\n",
    "                src_meta[\"type\"] = \"herb\"\n",
    "            elif domain in {\"ccd\",\"canine\"}:\n",
    "                src_meta[\"type\"] = \"ccd\"\n",
    "\n",
    "            for vec in self.to_2d(emb):\n",
    "                md = {\n",
    "                    \"type\": src_meta.get(\"type\", \"professional\"),\n",
    "                    \"content\": txt,\n",
    "                    **src_meta,            # 其餘欄位保留\n",
    "                }\n",
    "                all_embs.append(vec)\n",
    "                all_metas.append(md)\n",
    "                docs.append(txt)\n",
    "                all_ids.append(f\"text_{idx}\")\n",
    "                idx += 1\n",
    "\n",
    "        # -------------------- 圖片 --------------------\n",
    "        for j, img_name in enumerate(images):\n",
    "            full_path = str(self.image_dir / img_name)\n",
    "            emb = self.encode_image_to_vec(full_path)\n",
    "            if emb is None:\n",
    "                continue\n",
    "\n",
    "            src_meta = metadatas[j] if j < len(metadatas) else {}\n",
    "            if not isinstance(src_meta, dict):\n",
    "                src_meta = {\"note\": str(src_meta)}\n",
    "\n",
    "            md = {\n",
    "                \"type\": \"image\",\n",
    "                \"path\": img_name,\n",
    "                **src_meta,\n",
    "            }\n",
    "            for vec in self.to_2d(emb):\n",
    "                all_embs.append(vec)\n",
    "                all_metas.append(md)\n",
    "                docs.append(\"\")          # 占位\n",
    "                all_ids.append(f\"img_{idx}\")\n",
    "                idx += 1\n",
    "\n",
    "        # -------------------- 寫入 Chroma --------------------\n",
    "        if all_embs:\n",
    "            self.clip_collection.add(\n",
    "                embeddings = all_embs,\n",
    "                metadatas  = all_metas,\n",
    "                documents  = docs,\n",
    "                ids        = all_ids,\n",
    "            )\n",
    "            logger.info(f\"Added {len(all_embs)} items to '{self.collection_name}'\")\n",
    "\n",
    "\n",
    "    def similarity_search(self, query: str, k=25) -> Dict:\n",
    "        \"\"\"\n",
    "        對query做CLIP text embedding後,在clip_collection裡找最相似的k筆\n",
    "        \"\"\"\n",
    "        try:\n",
    "            emb = self.encode_text_to_vec(query)\n",
    "            if emb is None:\n",
    "                return {\"metadatas\":[],\"documents\":[],\"distances\":[]}\n",
    "        \n",
    "            results = self.clip_collection.query(\n",
    "                    query_embeddings=[emb],\n",
    "                    n_results=k,\n",
    "                    include=[\"distances\", \"metadatas\", \"documents\"]\n",
    "            ) \n",
    "            # ---------- ▌動態降權 + re-rank ----------------\n",
    "            q = query.lower()\n",
    "            if re.search(r\"(st|cv|gv|bl|pc)-\\d{1,2}|穴位\", q):\n",
    "                weight = {\"herb\": 0.3, \"ccd\": 0.3}     # acupoint = 1.0\n",
    "            elif any(w in q for w in [\"柴胡\", \"黃芩\", \"清熱\"]):\n",
    "                weight = {\"acupoint\": 0.3, \"ccd\": 0.3}\n",
    "            elif any(w in q for w in [\"認知\", \"nlrp3\", \"發炎\"]):\n",
    "                weight = {\"herb\": 0.3, \"acupoint\": 0.3}\n",
    "            else:\n",
    "                weight = {}\n",
    "\n",
    "            metas = results[\"metadatas\"][0]\n",
    "            dists = results[\"distances\"][0]\n",
    "            docs  = results[\"documents\"][0]\n",
    "\n",
    "            scored = []\n",
    "            for i, (m, d) in enumerate(zip(metas, dists)):\n",
    "                w = weight.get(m.get(\"type\", \"\"), 1.0)\n",
    "                scored.append((d * w, i))          # 距離愈小愈好\n",
    "            scored.sort(key=lambda x: x[0])\n",
    "\n",
    "            # idxs = [i for _, i in scored][:k]       # 取前 k\n",
    "            idxs = list(range(len(metas)))[:k]\n",
    "            \n",
    "            for key in [\"metadatas\", \"distances\", \"documents\"]:\n",
    "                results[key][0] = [results[key][0][i] for i in idxs]\n",
    "\n",
    "                return results\n",
    "        except Exception as e:\n",
    "            print(f\"Error in search: {str(e)}\")\n",
    "            return {\"metadatas\":[],\"documents\":[],\"distances\":[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 資料處理模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, embedding_processor: 'EmbeddingProcessor'):\n",
    "        self.embedding_processor = embedding_processor\n",
    "        \n",
    "    def extract_social_posts(self, csv_path: str) -> Tuple[List[Dict], List[str]]:\n",
    "        \"\"\"处理 CSV 并提取问答对和图片\"\"\"\n",
    "        logger.info(f\"Processing CSV: {csv_path}\")\n",
    "        qa_pairs = []\n",
    "        images = []\n",
    "        \n",
    "        df = pd.read_excel(csv_path)\n",
    "        current_post = None\n",
    "        current_responses = []\n",
    "        current_images = []\n",
    "        current_link = None\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            # 处理新的帖子\n",
    "            if pd.notna(row['post']):\n",
    "                # 保存前一个问答对\n",
    "                if current_post is not None:\n",
    "                    qa_pair = {\n",
    "                        'question': current_post,\n",
    "                        'answers': current_responses.copy(),\n",
    "                        'images': current_images.copy(),\n",
    "                        'metadata': {\n",
    "                            'type': 'social',\n",
    "                            'source': 'facebook',\n",
    "                            'images': ','.join(current_images) if current_images else '',\n",
    "                            'answer_count': len(current_responses),\n",
    "                            'link': current_link if current_link else ''\n",
    "                        }\n",
    "                    }\n",
    "                    if pd.notna(row.get('image_description')):\n",
    "                        qa_pair['metadata']['image_desc'] = row['image_description']\n",
    "\n",
    "                    qa_pairs.append(qa_pair)\n",
    "                    if current_images:\n",
    "                        images.extend(current_images)\n",
    "                \n",
    "                # 初始化新的问答对\n",
    "                current_post = row['post']\n",
    "                current_responses = []\n",
    "                current_images = []\n",
    "                current_link = row.get('link', '')\n",
    "            \n",
    "            # 添加回复\n",
    "            if pd.notna(row.get('responses')):\n",
    "                current_responses.append(row['responses'])\n",
    "            \n",
    "            # 处理图片\n",
    "            if pd.notna(row.get('images')):\n",
    "                img_path = row['images']\n",
    "                current_images.append(img_path)\n",
    "                logger.info(f\"Found image: {img_path} for current post\")\n",
    "  \n",
    "        \n",
    "        # 保存最后一个问答对\n",
    "        if current_post is not None and len(current_responses) >= 3:\n",
    "            qa_pair = {\n",
    "                'question': current_post,\n",
    "                'answers': current_responses,\n",
    "                'images': current_images,\n",
    "                'metadata': {\n",
    "                    'type': 'social_qa',\n",
    "                    'source': 'facebook',\n",
    "                    'images': ','.join(current_images) if current_images else '',\n",
    "                    'answer_count': len(current_responses),\n",
    "                    'link': current_link if current_link else ''\n",
    "                }\n",
    "            }\n",
    "            if pd.notna(row.get('image_description')):\n",
    "                    qa_pair['metadata']['image_desc'] = row['image_description']\n",
    "\n",
    "            qa_pairs.append(qa_pair)\n",
    "            if current_images:\n",
    "                images.extend(current_images)\n",
    "        \n",
    "        # 显示处理结果的详细信息\n",
    "        for i, qa in enumerate(qa_pairs):\n",
    "            logger.info(f\"\\nQA Pair {i+1}:\")\n",
    "            logger.info(f\"Question: {qa['question'][:100]}...\")\n",
    "            logger.info(f\"Number of answers: {len(qa['answers'])}\")\n",
    "            logger.info(f\"Images: {qa['images']}\")\n",
    "            logger.info(f\"Link: {qa.get('link', 'No link')}\")\n",
    "        \n",
    "        return qa_pairs, images\n",
    "\n",
    "    \n",
    "    def chunk_text(self,paragraph: str, chunk_size: int = 300, overlap: int = 50) -> List[str]:\n",
    "        \"\"\"\n",
    "        將給定段落，以 chunk_size 字符為上限進行切分，並且在 chunk 之間保留 overlap 個字的重疊，\n",
    "        以免上下文斷裂。\n",
    "        備註: \n",
    "        - 這裡以「字符」為單位，適合中文；英文也可用，但若想精確對英文 tokens 可改更先進方法。\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        start = 0\n",
    "        length = len(paragraph)\n",
    "\n",
    "        # 去掉前後多餘空白\n",
    "        paragraph = paragraph.strip()\n",
    "\n",
    "        while start < length:\n",
    "            end = start + chunk_size\n",
    "            # 取 substring\n",
    "            chunk = paragraph[start:end]\n",
    "            chunks.append(chunk)\n",
    "            # 移動指標(下一個 chunk)\n",
    "            # overlap 預防斷句失去上下文\n",
    "            start += (chunk_size - overlap)\n",
    "\n",
    "        return chunks\n",
    "  \n",
    "\n",
    "    def process_pdf(self, pdf_path: str,row_type: str) -> List[Dict]:\n",
    "        logger.info(f\"Processing PDF: {pdf_path}\")\n",
    "        professional_qa_pairs = []\n",
    "        pdf_name = Path(pdf_path).name  # 获取文件名\n",
    "        \n",
    "        try:\n",
    "            with open(pdf_path, 'rb') as file:\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                is_formula = self.detect_domain(pdf_name) == \"中醫方劑\"\n",
    "                is_acu = self.detect_domain(pdf_name) == \"針灸學\"\n",
    "\n",
    "\n",
    "                for page_num, page in enumerate(pdf_reader.pages):\n",
    "                    text = page.extract_text()\n",
    "                    print(f\"Page {page_num+1} raw text:\", repr(text))\n",
    "                    if is_formula:\n",
    "                        paragraphs = self.split_formula_blocks(text)\n",
    "                    elif is_acu:\n",
    "                        paragraphs = self.split_acu_blocks(text)\n",
    "                    else:\n",
    "                        paragraphs = text.split('\\n\\n')\n",
    "                    \n",
    "                    \n",
    "                    # 處理每個段落\n",
    "                    for para in paragraphs:\n",
    "                        # logger.info(f\"Para type: {type(para)}\")\n",
    "\n",
    "                        para_chunks = self.chunk_text(para)\n",
    "                        # logger.info(f\"Got {len(para_chunks)} chunks from chunk_text()\")\n",
    "\n",
    "                        for c in para_chunks:\n",
    "                            qa_pair = {\n",
    "                                'question': c[:50] + \"...\",  \n",
    "                                'answers': [c],\n",
    "                                'metadata': {\n",
    "                                    'type': row_type,\n",
    "                                    'source_file': pdf_name,  # 添加文件名\n",
    "                                    'page': str(page_num + 1),\n",
    "                                    'content_length': str(len(c))\n",
    "                                } #'domain':self.detect_domain(pdf_name),\n",
    "                            }\n",
    "                            professional_qa_pairs.append(qa_pair)\n",
    "                \n",
    "                logger.info(f\"Extracted {len(professional_qa_pairs)} paragraphs from {pdf_name}\")\n",
    "                return professional_qa_pairs\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing PDF {pdf_name}: {str(e)}\")\n",
    "            return []\n",
    "        \n",
    "    def detect_domain(self, pdf_name: str) -> str:\n",
    "        lower = pdf_name.lower()\n",
    "\n",
    "        if \"針灸\" in pdf_name or \"acupuncture\" in lower:\n",
    "            return \"針灸學\"\n",
    "        if \"herbal\" in lower or \"herbology\" in lower or \"方劑\" in pdf_name:\n",
    "            return \"中醫方劑\"\n",
    "        return \"其他\"\n",
    "    \n",
    "    def split_formula_blocks(self,text: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        用正則抓出『● 六味地黃丸』或『Liu Wei Di Huang Wan』開頭，\n",
    "        每遇下一個方名就結束上一塊\n",
    "        \"\"\"\n",
    "        pattern = re.compile(r\"(?:●|\\s)([\\u4e00-\\u9fffA-Za-z\\- ]{3,40}(?:湯|丸|飲|散|膏))\")\n",
    "        blocks = []\n",
    "        cur_block = []\n",
    "        for line in text.splitlines():\n",
    "            if pattern.search(line):\n",
    "                # 遇到下一帖藥 → 先收前一帖\n",
    "                if cur_block:\n",
    "                    blocks.append(\"\\n\".join(cur_block).strip())\n",
    "                    cur_block = []\n",
    "            cur_block.append(line)\n",
    "        if cur_block:\n",
    "            blocks.append(\"\\n\".join(cur_block).strip())\n",
    "        return [b for b in blocks if len(b) > 60]    \n",
    "\n",
    "    def split_acu_blocks(self,text: str) -> list[str]:\n",
    "        # 範例代碼：LI‑11、HT-7、SI 3\n",
    "        pattern = re.compile(r\"\\b([A-Z]{1,2}[ -‑]\\d{1,3})\\b\")\n",
    "        blocks, cur = [], []\n",
    "        for line in text.splitlines():\n",
    "            if pattern.search(line):\n",
    "                if cur: blocks.append(\"\\n\".join(cur).strip()); cur = []\n",
    "            cur.append(line)\n",
    "        if cur: blocks.append(\"\\n\".join(cur).strip())\n",
    "        return [b for b in blocks if len(b) > 40]\n",
    "\n",
    "    def process_all(self, csv_path: str, pdf_paths: List[str]):\n",
    "        \"\"\"綜合處理社群 CSV + PDFs\"\"\"\n",
    "        try:\n",
    "            social_qa_pairs, images = [], []  \n",
    "            # 1. 处理社群数据\n",
    "            if csv_path: \n",
    "                social_qa_pairs, images = self.extract_social_posts(csv_path)\n",
    "                logger.info(f\"\\nProcessed social data:\")\n",
    "                logger.info(f\"- Social QA pairs: {len(social_qa_pairs)}\")\n",
    "                logger.info(f\"- Images found: {len(images)}\")\n",
    "            else:\n",
    "                logger.info(\"Skip social CSV, only處理 PDFs\")\n",
    "            # 检查图片文件\n",
    "            valid_images = []\n",
    "            for img in images:\n",
    "                img_path = Path(self.embedding_processor.image_dir) / img\n",
    "                if img_path.exists():\n",
    "                    valid_images.append(img)\n",
    "            \n",
    "            # 2. 处理所有 PDF\n",
    "            all_professional_pairs = []\n",
    "            for pdf_path in pdf_paths:\n",
    "                pdf_name = pdf_path.name.lower()\n",
    "                for t, keys in TYPE_MAP.items():\n",
    "                    if any(k in pdf_name for k in keys):\n",
    "                        row_type = t; break\n",
    "                else:\n",
    "                    row_type = \"professional\"\n",
    "                pdf_qa_pairs = self.process_pdf(pdf_path, row_type=row_type)\n",
    "                #pdf_qa_pairs = self.process_pdf(pdf_path)\n",
    "                all_professional_pairs.extend(pdf_qa_pairs)\n",
    "                logger.info(f\"\\nProcessed {Path(pdf_path).name}:\")\n",
    "                logger.info(f\"- Extracted paragraphs: {len(pdf_qa_pairs)}\")\n",
    "            \n",
    "            # 3. 合并 => all_qa_pairs\n",
    "            all_qa_pairs = social_qa_pairs + all_professional_pairs\n",
    "            \n",
    "            # 4. 準備 texts + metadatas => 你就能一次或多次呼叫 add_vectors\n",
    "            questions = []\n",
    "            answers = []\n",
    "            question_metas = []\n",
    "            answer_metas = []\n",
    "            \n",
    "            # 处理所有问答对\n",
    "            for qa_pair in all_qa_pairs:\n",
    "                # question \n",
    "                questions.append(qa_pair['question'])\n",
    "                question_metas.append(qa_pair['metadata'])\n",
    "                \n",
    "                # answers\n",
    "                for ans_text in qa_pair['answers']:\n",
    "                    answers.append(ans_text)\n",
    "                    am = qa_pair['metadata'].copy()\n",
    "                    am['parent_question'] = qa_pair['question']\n",
    "                    answer_metas.append(am)\n",
    "\n",
    "            # ------------- 這裡才開始組 professional texts / metas -------------\n",
    "            prof_texts = [qa[\"answers\"][0] for qa in all_professional_pairs]\n",
    "            prof_metas = [qa[\"metadata\"]   for qa in all_professional_pairs]\n",
    "\n",
    "            \n",
    "            # 输出处理结果\n",
    "            logger.info(f\"\\nFinal processing summary:\")\n",
    "            logger.info(f\"- Total questions: {len(questions)}\")\n",
    "            logger.info(f\"- Total answers: {len(answers)}\")\n",
    "            logger.info(f\"- Valid images: {len(valid_images)}\")\n",
    "            logger.info(f\"- Social content: {len(social_qa_pairs)} QA pairs\")\n",
    "            logger.info(f\"- Professional content: {len(all_professional_pairs)} paragraphs\")\n",
    "            \n",
    "\n",
    "\n",
    "            # --------- 🔧 把 3 組 metadata 都保證是 dict (放在此處) ---------\n",
    "            question_metas = [m if isinstance(m, dict) else {\"note\": str(m)}\n",
    "                            for m in question_metas]\n",
    "            prof_metas     = [m if isinstance(m, dict) else {\"note\": str(m)}\n",
    "                            for m in prof_metas]\n",
    "            # 若要用 answer_metas 也一併處理\n",
    "            answer_metas   = [m if isinstance(m, dict) else {\"note\": str(m)}\n",
    "                            for m in answer_metas]\n",
    "\n",
    "            # 5. 全部寫進clip_collection\n",
    "            \n",
    "            \n",
    "            # (C) professional paragraphs\n",
    "            # prof_texts  = [qa[\"answers\"][0] for qa in all_professional_pairs]\n",
    "            # prof_metas  = [qa[\"metadata\"]   for qa in all_professional_pairs]\n",
    "\n",
    "            self.embedding_processor.add_vectors(texts=prof_texts,\n",
    "                                            metadatas=prof_metas)\n",
    "            \n",
    "            # (A) 先加所有 question\n",
    "            self.embedding_processor.add_vectors(\n",
    "                texts = questions,\n",
    "                metadatas = question_metas\n",
    "            )\n",
    "\n",
    "            # (B) 再加所有 answers\n",
    "            # self.embedding_processor.add_vectors(\n",
    "            #     texts = answers,\n",
    "            #     metadatas = answer_metas\n",
    "            # )\n",
    "            \n",
    "            # (D) 再加 images\n",
    "            # 沒有對應metadata？可以簡單做\n",
    "            # [{\"type\":\"image\",\"source\":\"facebook\"} ...] 或\n",
    "            # 想知道它屬於哪個QApair? 就要自己對應\n",
    "            if valid_images:\n",
    "                meta_for_imgs = []\n",
    "                for img_name in valid_images:\n",
    "                    meta_for_imgs.append({\n",
    "                        \"type\":\"image\",\n",
    "                        \"source\":\"facebook\",\n",
    "                        \"filename\": img_name\n",
    "                    })\n",
    "\n",
    "                self.embedding_processor.add_vectors(\n",
    "                    images=valid_images,\n",
    "                    metadatas=meta_for_imgs\n",
    "                )\n",
    "\n",
    "            logger.info(\"All data added to clip_collection.\")\n",
    "            return len(questions), len(valid_images)\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing documents: {str(e)}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QA系統模組"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "class QASystem:\n",
    "    def __init__(self, embedding_processor: 'EmbeddingProcessor',\n",
    "                 model_name: str = 'llama3.2-vision'):\n",
    "        self.embedding_processor = embedding_processor\n",
    "        self.model_name = model_name\n",
    "        logger.info(f\"Initialized QA System with Ollama model: {model_name}\")\n",
    "\n",
    "    def _classify_collection_results(self, raw_result) -> Dict:\n",
    "        \"\"\"\n",
    "        將 clip_collection 的檢索結果 (metadatas/documents...) \n",
    "        轉換成 { 'social': {...}, 'professional': {...}, 'images': {...} } \n",
    "        的結構，便於後續 gather_references / format_context。\n",
    "        \"\"\"\n",
    "        # 預設空結構\n",
    "        structured = {\n",
    "            \"social\": {\n",
    "                \"metadata\": [],\n",
    "                \"link\": [],\n",
    "                \"content\": [],\n",
    "                \"documents\":[]\n",
    "            },\n",
    "            \"professional\": {\n",
    "                \"metadata\": [],\n",
    "                \"content\": [],\n",
    "                \"documents\":[]\n",
    "                # ...\n",
    "            },\n",
    "            \"images\": {\n",
    "                \"metadata\": [],\n",
    "                \"paths\": [],\n",
    "                \"relevance\":[]\n",
    "            },\n",
    "            \n",
    "        }\n",
    "\n",
    "        # raw_result[\"metadatas\"] 是個 2D list => [ [meta0, meta1, ...] ]\n",
    "        if raw_result.get(\"metadatas\"):\n",
    "            meta_list = raw_result[\"metadatas\"][0]  # 因為只有1個 query\n",
    "            dist_list = raw_result[\"distances\"][0] if raw_result.get(\"distances\") else []\n",
    "            doc_list = raw_result[\"documents\"][0]\n",
    "            ids_list  = raw_result[\"ids\"][0] if raw_result.get(\"ids\") else []\n",
    "            # documents_list = raw_result[\"documents\"][0]\n",
    "\n",
    "            for i, meta in enumerate(meta_list):\n",
    "                dist = dist_list[i] if i < len(dist_list) else None\n",
    "                doc_id = ids_list[i] if i < len(ids_list) else \"\"\n",
    "                doc_text = doc_list[i] if i < len(doc_list) else \"\"\n",
    "\n",
    "                # 判斷 metadata 是屬於哪個來源\n",
    "                # 例如 meta.get(\"type\") == \"social_qa\" => 放到 social\n",
    "                #     meta.get(\"type\") == \"professional\" => 放到 professional\n",
    "                #     meta.get(\"type\") == \"image\" => 放到 images\n",
    "                src_type = meta.get(\"type\",\"\")\n",
    "\n",
    "                if src_type == \"social\":\n",
    "                    structured[\"social\"][\"metadata\"].append(meta)\n",
    "                    structured[\"social\"][\"documents\"].append(doc_text)\n",
    "                elif src_type in (\"acupoint\", \"herb\", \"ccd\", \"professional\"):\n",
    "                    structured[\"professional\"][\"metadata\"].append(meta)\n",
    "                    structured[\"social\"][\"documents\"].append(doc_text)\n",
    "                \n",
    "                elif src_type == \"image\":\n",
    "                    structured[\"images\"][\"metadata\"].append(meta)\n",
    "                    # 放 path\n",
    "                    path = meta.get(\"path\",\"\")\n",
    "                    structured[\"images\"][\"paths\"].append(path)\n",
    "                    structured[\"images\"][\"relevance\"].append(dist)\n",
    "\n",
    "                else:\n",
    "                    # 將未知 type 全丟 professional，或依需求改 social\n",
    "                    meta.setdefault(\"type\", \"professional\")\n",
    "                    structured[\"professional\"][\"metadata\"].append(meta)\n",
    "                    structured[\"professional\"][\"documents\"].append(doc_text)\n",
    "\n",
    "\n",
    "        return structured\n",
    "\n",
    "\n",
    "    def determine_question_type(self,query: str) -> str:\n",
    "        \"\"\"\n",
    "        回傳: \"multiple_choice\" | \"true_false\" | \"qa\"\n",
    "        支援中英文 & 各種標點\n",
    "        \"\"\"\n",
    "        q = query.strip().lower()\n",
    "\n",
    "        # --- Multiple‑choice --------------------------------------------------\n",
    "        # 1) 行首或換行後出現  A～D / 全形Ａ～Ｄ / 「答」，\n",
    "        #    後面接　. ． : ： 、)\n",
    "        mc_pattern = re.compile(r'(?:^|\\n)\\s*(?:[a-dａ-ｄ]|答)[:\\.．:：、\\)]', re.I)\n",
    "        # 2) or 句子帶 \"which of the following\"\n",
    "        mc_keywords_en = [\"which of the following\", \"which one of the following\",\n",
    "                        \"which option\", \"choose one of\"]\n",
    "\n",
    "        if mc_pattern.search(query) or any(kw in q for kw in mc_keywords_en):\n",
    "            return \"multiple_choice\"\n",
    "\n",
    "        # --- True / False -----------------------------------------------------\n",
    "        tf_keywords_zh = [\"是否\", \"是嗎\", \"對嗎\", \"正確嗎\"]\n",
    "        tf_keywords_en = ['true or false', 'is it', 'is this', 'is that', \n",
    "             'is it possible', 'correct or not']\n",
    "\n",
    "        if any(k in q for k in tf_keywords_zh + tf_keywords_en):\n",
    "            return \"true_false\"\n",
    "\n",
    "        # --- Default ----------------------------------------------------------\n",
    "        return \"qa\"\n",
    "\n",
    "    def gather_references(self, search_results: Dict) -> str:\n",
    "        \"\"\"\n",
    "        從 search_results 中擷取 PDF 檔名/社群連結，並組成一個字串\n",
    "        \"\"\"\n",
    "        if not isinstance(search_results, dict):\n",
    "            logger.error(\"search_results 格式錯誤: %s\", type(search_results))\n",
    "            return \"\"\n",
    "\n",
    "        references = []\n",
    "\n",
    "        # 處理 social\n",
    "        for meta in search_results[\"social\"].get(\"metadata\", []):\n",
    "            if meta.get(\"type\") == \"social_qa\" and \"link\" in meta:\n",
    "                references.append(f\"(經驗) {meta['link']}\")\n",
    "\n",
    "        # 處理 professional\n",
    "        for meta in search_results[\"professional\"].get(\"metadata\", []):\n",
    "            if meta.get(\"type\") in [\"pdf\", \"professional\"]:\n",
    "                pdf_name = meta.get(\"source_file\", \"unknown.pdf\")\n",
    "                references.append(f\"(文獻) {pdf_name}\")\n",
    "\n",
    "        # 去重\n",
    "        unique_refs = list(set(references))\n",
    "        return \"\\n\".join(unique_refs)\n",
    "\n",
    "\n",
    "    def build_user_prompt(\n",
    "        self,\n",
    "        query: str,\n",
    "        context: str,\n",
    "        references_str: str = \"\"\n",
    "        ) -> str:\n",
    "        # 不含任何格式規範！只給題目與資料\n",
    "        return (\n",
    "            f\"{query}\\n\\n\"\n",
    "            \"參考資料：\\n\" + context +\n",
    "            \"\\n來源：\\n\" + references_str\n",
    "        )\n",
    "\n",
    "       \n",
    "    def translate_en_to_zh(self,chinese_text: str) -> str:\n",
    "        try:\n",
    "            # 指定原文語言為 'zh'（中文），目標語言為 'en'（英文）\n",
    "            translator = GoogleTranslator(source='en', target='zh-TW')\n",
    "            result = translator.translate(chinese_text)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            print(f\"翻譯錯誤：{e} - 對應中文問題：{chinese_text}\")\n",
    "            return chinese_text  # 若翻譯失敗，返回原文\n",
    "\n",
    "\n",
    "    def merge_adjacent(self, metas, docs, k_keep: int = 5) -> str:\n",
    "        \"\"\"\n",
    "        將同檔同頁且 _id 連號的片段合併，回傳前 k_keep 段文字。\n",
    "        參數\n",
    "        ----\n",
    "        metas : list[dict]    # raw_result[\"metadatas\"][0]\n",
    "        docs  : list[str]     # raw_result[\"documents\"][0]\n",
    "        \"\"\"\n",
    "        ID_NUM_RE = re.compile(r\"_(\\d+)$\")   # 尾碼取數字：text_123 → 123\n",
    "        merged, buf = [], \"\"\n",
    "        last_src, last_idx = (\"\", \"\"), -999\n",
    "\n",
    "        for md, doc in zip(metas, docs):\n",
    "            src_key = (md.get(\"source_file\", \"\"), md.get(\"page\", \"\"))\n",
    "\n",
    "            # 取 _id 尾碼；若不存在則設 -1\n",
    "            _id = md.get(\"_id\", \"\")\n",
    "            m = ID_NUM_RE.search(_id)\n",
    "            cur_idx = int(m.group(1)) if m else -1\n",
    "\n",
    "            # 同檔同頁且連號 → 視為相鄰\n",
    "            if src_key == last_src and cur_idx == last_idx + 1:\n",
    "                buf += doc\n",
    "            else:\n",
    "                if buf:\n",
    "                    merged.append(buf)\n",
    "                buf = doc\n",
    "            last_src, last_idx = src_key, cur_idx\n",
    "\n",
    "        if buf:\n",
    "            merged.append(buf)\n",
    "\n",
    "        return \"\\n\\n\".join(merged[:k_keep])\n",
    "\n",
    "\n",
    "    def generate_response(self, query: str,question_type: Optional[str] = None) -> Tuple[str, List[str]]:\n",
    "        try:\n",
    "            TARGET_DOMAIN = \"\" \n",
    "            raw_result = self.embedding_processor.similarity_search(\n",
    "                query,\n",
    "                k=25,\n",
    "                domain=TARGET_DOMAIN)  \n",
    "            print(raw_result[\"metadatas\"])\n",
    "            # ↓↓↓ 直接加這 2 行（只留在除錯期間）\n",
    "            hit_types = [m[\"type\"] for m in raw_result[\"metadatas\"][0][:10]]\n",
    "            print(\"[DEBUG] top-10 types:\", hit_types)\n",
    "            # ↑↑↑\n",
    "\n",
    "            # ── 動態依 type 調分，補回候選列表 ────────────────\n",
    "            # metas = raw_result[\"metadatas\"][0]\n",
    "            # docs  = raw_result[\"documents\"][0]\n",
    "            # sims  = raw_result[\"distances\"][0]\n",
    "\n",
    "            # # 依題目關鍵字決定 penalty\n",
    "            # q = query.lower()\n",
    "            # if re.search(r\"(st-|pc-|cv-|gv-|bl-)\\d{1,2}|穴位\", q):\n",
    "            #     penalty = {\"herb\": 0.6, \"ccd\": 0.7}\n",
    "            # elif any(w in q for w in [\"柴胡\",\"黃芩\",\"清熱\",\"解毒\"]):\n",
    "            #     penalty = {\"acupoint\": 0.7, \"ccd\": 0.7}\n",
    "            # elif any(w in q for w in [\"認知\",\"失智\",\"nlrp3\",\"發炎\"]):\n",
    "            #     penalty = {\"herb\": 0.6, \"acupoint\": 0.7}\n",
    "            # else:\n",
    "            #     penalty = {}\n",
    "\n",
    "            # scored = [\n",
    "            #     (score * penalty.get(md[\"type\"], 1.0), md, doc)\n",
    "            #     for score, md, doc in zip(sims, metas, docs)\n",
    "            # ]\n",
    "            # # 重新排序並取前 k_keep=8\n",
    "            # scored.sort(key=lambda x: x[0], reverse=True)\n",
    "            # metas, docs = zip(*[(m, d) for _, m, d in scored[:8]])\n",
    "\n",
    "            # # 把處理後的 metas / docs 回傳給下游\n",
    "            # raw_result[\"metadatas\"][0] = list(metas)\n",
    "            # raw_result[\"documents\"][0] = list(docs)\n",
    "            # ────────────────────────────────────────────\n",
    "\n",
    "            \n",
    "            # ← 新增保險\n",
    "            if not raw_result[\"documents\"] or len(raw_result[\"documents\"][0]) == 0:\n",
    "                logger.warning(\"No hits for query → 改用 k=50 再試一次\")\n",
    "                raw_result = self.embedding_processor.similarity_search(query, k=50)\n",
    "\n",
    "            if not raw_result[\"documents\"] or len(raw_result[\"documents\"][0]) == 0:\n",
    "                # 還是空，直接回覆 [NoRef]\n",
    "                return \"[NoRef] 無足夠證據判斷\", []\n",
    "            \n",
    "            # 用後處理\n",
    "            search_results = self._classify_collection_results(raw_result)\n",
    "            logger.info(\"SEARCH RESULT(structured): %s\",search_results)\n",
    "\n",
    "\n",
    "            metas = raw_result[\"metadatas\"][0]\n",
    "            docs  = raw_result[\"documents\"][0]\n",
    "\n",
    "            # context = self.format_context(search_results)\n",
    "            # raw_ctx = self.merge_adjacent(metas, docs, k_keep=5)[:1500]\n",
    "            context = self.merge_adjacent(raw_result[\"metadatas\"][0],\n",
    "                              raw_result[\"documents\"][0])[:1500]\n",
    "\n",
    "            context = context[:1500]          # 最多 1500 字\n",
    "\n",
    "            references_str = self.gather_references(search_results)\n",
    "            # link應該用傳參數的會成功 可能用context.link之類的抓題目的reference\n",
    "            \n",
    "            zh_query = self.translate_en_to_zh(query)\n",
    "            \n",
    "\n",
    "            # --- ① 題型 --------------------------------------------------------\n",
    "            q_type = question_type or self.determine_question_type(query)\n",
    "\n",
    "            user_prompt = self.build_user_prompt(\n",
    "                query=query,\n",
    "                context=context[:1500],\n",
    "                references_str=references_str\n",
    "            )\n",
    "            # ---------- ② 根據題型動態組 system 指令 ----------\n",
    "            if q_type == \"multiple_choice\":\n",
    "                format_rules = (\n",
    "                    \"這是一題選擇題，回答格式如下：\\n\"\n",
    "                    \"先根據題目整理參考資訊、你的理解與常識\\n\"\n",
    "                    \"用 2-3 句話說明理由。\\n\"\n",
    "                    \"請在答案最後顯示你參考的來源連結或論文名稱，如果來源中包含「(經驗) some_link」，請在回答中以 [Experience: some_link] 形式標示；若包含「(文獻) some.pdf」，就 [reference: some.pdf]\\n\"\n",
    "                    \"如檢索結果仍無相關資訊，請以[NoRef]標示並根據你的常識回答。\"\n",
    "                    \"最後再回答答案，只能回答 A/B/C/D (請勿帶任何標點、文字、也不要只回答選項)\\n\"\n",
    "                    \"若同時出現多個選項，請只選一個最適合的\\n\"\n",
    "                    \"問題如下：\\n\"\n",
    "                )\n",
    "            elif q_type == \"true_false\":\n",
    "                format_rules = (\n",
    "                    \"這是一題是非題，請按照下列格式回答：\\n\"\n",
    "                    \"先根據題目整理參考資訊、你的理解與常識\\n\"\n",
    "                    \"請在答案最後顯示你參考的來源連結或論文名稱，如果來源中包含「(經驗) some_link」，請在回答中以 [Experience: some_link] 形式標示；若包含「(文獻) some.pdf」，就 [reference: some.pdf]\\n\"\n",
    "                    \"如檢索結果仍無相關資訊，請以[NoRef]標示並根據你的常識回答。\\n\"\n",
    "                    \"最後再給出結論，只能寫「True」或「False」\\n\"\n",
    "                    \"問題如下：\\n\"\n",
    "                )\n",
    "            else:   # qa\n",
    "                format_rules = (\n",
    "                    \"請依以下格式回答：\\n\"\n",
    "                    \"針對問題提供具體答案 \\n\"\n",
    "                    \"請在答案最後顯示你參考的來源連結或論文名稱，如果來源中包含「(經驗) some_link」，請在回答中以 [Experience: some_link] 形式標示；若包含「(文獻) some.pdf」，就 [reference: some.pdf]\\n\"\n",
    "                    \"若遇到無法確定或證據不足的情況可以補充說明研究不足，請以[NoRef]標示並根據你的常識回答。\\n\"\n",
    "                    \"問題如下：\\n\"\n",
    "                )\n",
    "\n",
    "            system_prompt = (\n",
    "                \"您是一名專業獸醫，1.擅長犬認知功能障礙綜合症（CCD）的診斷和護理 2.擁有豐富的寵物中醫知識 3.常見問題診斷及改善建議\\n\"\n",
    "                + format_rules\n",
    "            )\n",
    "        \n",
    "            message = [\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\",   \"content\": user_prompt}\n",
    "            ]\n",
    "            print(\"=======sys prompt =======\",system_prompt)\n",
    "            print(\"=======user prompt =======\",user_prompt)\n",
    "            # 處理圖片\n",
    "            image_paths = []\n",
    "            # 2) 從 social metadata 把圖片撈出\n",
    "            for md in search_results[\"social\"][\"metadata\"]:\n",
    "                if md.get(\"images\"):  # e.g. \"image12.jpg,image02.jpg\"\n",
    "                    for img_name in md[\"images\"].split(\",\"):\n",
    "                        img_name = img_name.strip()\n",
    "                        if img_name:\n",
    "                            full_path = self.embedding_processor.image_dir / img_name\n",
    "                            if full_path.exists():\n",
    "                                image_paths.append(str(full_path.resolve()))\n",
    "            # 3) OLlama 只允許一張, 你可取 image_paths[:1] => message[\"images\"] = ...\n",
    "            if image_paths:\n",
    "                print(\"We found images: \", image_paths)\n",
    "                # 你可以先隨便取一張\n",
    "                # or 全部 inject to prompt\n",
    "            else:\n",
    "                logger.info(\"No images to display\")\n",
    "\n",
    "            # 生成响应\n",
    "            response = ollama.chat(\n",
    "                model=self.model_name,\n",
    "                messages=message\n",
    "            )\n",
    "            return response['message']['content'], image_paths\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error generating response: {str(e)}\")\n",
    "            # return f\"出現問題，檢查ollama連線或是generate_response\", []\n",
    "            raise\n",
    "\n",
    "    def format_context(self, search_results: Dict) -> str:\n",
    "        \"\"\"Format context from search results\"\"\"\n",
    "        try:\n",
    "            context = \"\"\n",
    "\n",
    "            # 1) 處理社群討論\n",
    "            social_metas = search_results[\"social\"].get(\"metadata\", [])\n",
    "            social_links = search_results[\"social\"].get(\"link\", [])\n",
    "            social_docs = search_results[\"social\"].get(\"documents\", [])\n",
    "            social_content = search_results[\"social\"].get(\"content\", [])\n",
    "\n",
    "            if social_metas or social_links or social_docs:\n",
    "                context += \"\\n[社群討論]\\n\"\n",
    "                # 這裡示範把 link、documents 都輸出\n",
    "                for i, meta in enumerate(social_metas):\n",
    "                    link_str = meta.get(\"link\", \"\")\n",
    "                    doc_text = social_docs[i] if i < len(social_docs) else \"\"\n",
    "                    context += f\"【Link】{link_str}\\n\" if link_str else \"\"\n",
    "                    # doc_text 就是檢索回來的 chunk\n",
    "                    context += f\"【討論片段】{doc_text}\\n\\n\"\n",
    "\n",
    "            # 2) 處理專業文獻\n",
    "            prof_metas = search_results[\"professional\"].get(\"metadata\", [])\n",
    "            prof_docs = search_results[\"professional\"].get(\"documents\", [])\n",
    "\n",
    "            if prof_metas or prof_docs:\n",
    "                context += \"\\n[專業文獻]\\n\"\n",
    "                for j, meta in enumerate(prof_metas):\n",
    "                    source_file = meta.get(\"source_file\", \"\")\n",
    "                    doc_text = prof_docs[j] if j < len(prof_docs) else \"\"\n",
    "                    # 如果您有另外存放頁碼 page = meta.get(\"page\"), 也可列出\n",
    "                    page_num = meta.get(\"page\", \"\")\n",
    "                    context += f\"【文件片段】{doc_text}\\n\"\n",
    "                    if source_file:\n",
    "                        context += f\"(檔案: {source_file}\"\n",
    "                        context += f\", 頁: {page_num})\" if page_num else \")\"\n",
    "                    context += \"\\n\\n\"\n",
    "\n",
    "            # 偵錯用 (可保留也可移除)\n",
    "            print(\"social metadata:\", social_metas)\n",
    "            print(\"social links:\", social_links)\n",
    "            print(\"professional metadata:\", prof_metas)\n",
    "\n",
    "            return context if context.strip() else \"參考資料無法取得\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error formatting context: {str(e)}\")\n",
    "            return \"Unable to retrieve reference materials\"\n",
    "\n",
    "\n",
    "    def display_response(self, query: str,question_type: Optional[str] = None):\n",
    "            \"\"\"Display response with text and images\"\"\"\n",
    "            try:\n",
    "                logger.info(\"Starting to generate response...\")\n",
    "                try:\n",
    "                    response_text, image_paths = self.generate_response(query,question_type)\n",
    "                except Exception as e:\n",
    "                    response_text = f\"[ERROR] {e}\"\n",
    "                    image_paths = []\n",
    "                \n",
    "                print(\"Question:\", query)\n",
    "                print(\"\\nSystem Response:\")\n",
    "                print(response_text)\n",
    "                print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "                if image_paths:\n",
    "                    print(\"\\nRelated Image:\")\n",
    "                    img_path = image_paths[0]  # We now only have one image\n",
    "                    try:\n",
    "                        img = PILImage.open(img_path)\n",
    "                        display(IPyImage(filename=img_path))\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"Error displaying image {img_path}: {str(e)}\")\n",
    "                else:\n",
    "                    logger.info(\"No images to display\")\n",
    "\n",
    "\n",
    "                return response_text, image_paths # add for response 0406\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error in display_response: {str(e)}\", exc_info=True)  \n",
    "                return \"\", [] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 題目測試"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 單一題目測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 測試查詢\n",
    "test_queries = [\n",
    "# \"CCD 是否與神經發炎相關？有無特定細胞因子（cytokines）或發炎路徑（例如NLRP3 inflammasome）參與？\",\n",
    "# \"CCD 是否與腸道微生物群變化有關？是否有特定細菌群落會影響大腦健康？\",\n",
    "# \" 失智犬的松果體是否退化\",\n",
    "# \" 有刻板形為的犬隻是否會增加CCD風險？\",\n",
    "# \" 失智犬分泌褪黑激素的能力是否退化？\",\n",
    "# \" 皮質類固醇cortisol或應激荷爾蒙stress hormones是否可作為 CCD 的潛在診斷指標？\",\n",
    "# \" 如何區分正常老化與CCD的早期徵兆？ \",\n",
    "# \" B 群維生素是否能降低 CCD 進展風險？\",\n",
    "# \" 食用GABA是否對於預防CCD有效？\",\n",
    "# \" 警犬、救難犬等工作犬在罹患CCD的機率比較家庭陪伴犬\",\n",
    "# \" 目前是否有影像學檢測可以準確區分 CCD 與其他神經退行性疾病？\",\n",
    "# \" 如果CCD進展到最後階段，哪些症狀最需要關注？如何平衡狗狗的生活質量與疼痛管理，並且決定狗狗未來的方向\",\n",
    "\n",
    "# \"根據資料中對犬認知功能障礙（CCD）神經發炎機制的探討，NLRP3炎症小體在分子層面上如何參與CCD進程？該過程涉及哪些關鍵細胞因子與調控機制？\",\n",
    "# \"資料提到腸道微生物群與CCD之間可能存在聯繫，請問文中如何闡述腸道菌群失衡影響神經傳導與免疫反應的分子機制？哪些特定細菌群落的變化被認為與CCD進展相關？\",\n",
    "# \"在探討CCD的診斷策略中，該資料對於利用影像學技術（如MRI與CT）區分CCD與其他神經退行性疾病的應用提出了哪些見解？這些技術的優勢與局限性分別是什麼？\",\n",
    "# \"資料中對失智犬松果體退化與褪黑激素分泌減少之間的關聯有詳細論述，請問該研究如何描述這一生理變化的分子機制以及其對犬隻睡眠-覺醒週期的影響？\",\n",
    "# \"針對CCD的治療策略，資料中提出了哪些基於分子機制的治療方法？請分析這些方法在臨床應用上的現狀、潛在優勢及未來研究中亟待解決的挑戰。\",\n",
    "\n",
    "# \"哪種犬容易失智？\",\n",
    "# \"大中小型狗的失智照顧方式有什麼不同？\"\n",
    "# \"我的狗狗有失智症，晚上總是繞圈圈而且叫個不停，有什麼方法能幫助牠安靜下來睡覺嗎？有人推薦過褪黑激素，這真的有效嗎？\",\n",
    "# \"我的老狗有認知障礙，經常卡在角落或家具間不知道如何脫困，有什麼環境安排和居家照護措施可以幫助牠更舒適地生活？其他飼主都是怎麼處理這種情況的？有相關照片嗎？\",\n",
    "# \"給我一些照護環境的圖片\",\n",
    "# \"針對年長犬隻可能出現的神經病理變化，哪些關鍵指標常被用來對比阿茲海默類型的退化症狀，並且與臨床觀察到的行為衰退有何關聯？\",\n",
    "# \"除了藥物介入之外，平時飼養管理與環境調整方面有哪些具體作法，能同時有助於失智犬與失智貓維持較佳的生活品質，並為何多種方式並用的照護策略往往更能延緩認知退化？\",\n",
    "# \"若以老犬作為模擬人類老化與失智的實驗模型，進行認知增益或治療性藥物的評估時，最常採用哪些評量方法來確認藥物對行為和神經功能的影響，並且在哪些神經傳導路徑上通常會看到較明顯的指標性變化？\",\n",
    "# \"In older dogs, which key indicators are commonly used to compare with Alzheimer-type degeneration, and how do these indicators relate to clinically observed behavioral decline?\",\n",
    "# \"Beyond pharmacological intervention, which specific management and environmental adjustments help senior dogs and cats with cognitive impairment maintain a higher quality of life, and why does combining multiple caregiving strategies often slow cognitive decline more effectively?\",\n",
    "# \"When using senior dogs as a model for human aging and dementia to evaluate cognitive-enhancing or therapeutic drugs, what assessment methods are most commonly employed to gauge the drug’s effects on behavior and neurological function, and in which neurotransmission pathways are the most prominent changes typically observed?\"\n",
    "\"在評估犬隻 CCD 的臨床症狀時，下列哪一項行為面向最常被列為主要觀察指標之一? A. 毛色是否變白 B. 飲水量的增加 C. 定向能力 (Orientation) 與空間辨識度 D. 心跳與呼吸速率\"\n",
    "\n",
    "                    ]\n",
    "\n",
    "for query in test_queries:\n",
    "    qa_system.display_response(query)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initializing Chroma with directory: chroma_db\n",
      "INFO:__main__:Using collection 'clip_collection' (dimension=768, reset=False)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "TEST_MODE = False                           # ← 切換開關\n",
    "COLLECTION_NAME = \"clip_collection\"   # 測試用向量庫\n",
    "\n",
    "# 1) 初始化 embedding_processor，傳入新的 collection_name\n",
    "embedding_processor = EmbeddingProcessor(\n",
    "    image_size=(224, 224) ,\n",
    "    collection_name=COLLECTION_NAME,    # ★若 __init__ 沒這參數，改下方註解方法\n",
    "    reset=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重建DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 初始化資料處理器\n",
    "data_processor = DataProcessor(embedding_processor)\n",
    "\n",
    "# 3) 指定測試或正式資料夾\n",
    "rag_data_dir = Path(\"RAG_data_test\" if TEST_MODE else \"RAG_data\")\n",
    "pdf_paths = list(rag_data_dir.glob(\"*.pdf\"))\n",
    "\n",
    "\n",
    "print(\"找到以下 PDF：\")\n",
    "for p in pdf_paths: print(\" -\", p.name)\n",
    "\n",
    "# 4) 處理資料 （CSV 你可以傳 None 代表不處理社群資料）\n",
    "_ = data_processor.process_all(\n",
    "    csv_path=\"post_response_filtered.xlsx\",           # 只測 PDF，可先不管社群\n",
    "    pdf_paths=pdf_paths\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QA System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Initialized QA System with Ollama model: llama3.2-vision\n"
     ]
    }
   ],
   "source": [
    "# 建立 QA 系統，沿用同一個 embedding_processor\n",
    "qa_system = QASystem(\n",
    "    embedding_processor=embedding_processor,\n",
    "    model_name='llama3.2-vision'\n",
    ")\n",
    "# TARGET_DOMAIN = \"\"   # 想測哪個就填哪個\n",
    "# qa_system.TARGET_DOMAIN = TARGET_DOMAIN   # 若你寫成屬性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_zh_to_en(chinese_text: str) -> str:\n",
    "    try:\n",
    "        # 指定原文語言為 'zh'（中文），目標語言為 'en'（英文）\n",
    "        translator = GoogleTranslator(source='zh-TW', target='en')\n",
    "        result = translator.translate(chinese_text)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"翻譯錯誤：{e} - 對應中文問題：{chinese_text}\")\n",
    "        return chinese_text  # 若翻譯失敗，返回原文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_llm_answer(llm_response: str, q_type: str) -> str:\n",
    "    \"\"\"\n",
    "    根據題型 (選擇 or 是非)，從 LLM 的回覆字串中解析出可能的最終答案。\n",
    "    \"\"\"\n",
    "    if not llm_response or not llm_response.strip():\n",
    "        return \"\" \n",
    "\n",
    "    # 把回覆都轉小寫，以便搜尋\n",
    "    q_type = q_type.strip().lower()        # 保險起見\n",
    "    cleaned = llm_response.strip()\n",
    "    lines = [ln.strip() for ln in llm_response.splitlines() if ln.strip()]\n",
    "    \n",
    "    \n",
    "    if q_type == \"multiple_choice\":\n",
    "       \n",
    "         # 先抓最後一行\n",
    "        last = lines[-1]\n",
    "        if re.fullmatch(r\"[ABCDabcd]\", last):\n",
    "            return last.upper()\n",
    "        # fallback：找 '答案：B'\n",
    "        m = re.search(r\"答案[:：\\s]*([ABCDabcd])\", llm_response)\n",
    "        return m.group(1).upper() if m else \"\"\n",
    "    \n",
    "    elif q_type == \"true_false\":\n",
    "\n",
    "        for line in reversed(llm_response.splitlines()):\n",
    "            line = line.strip().lower()\n",
    "            if line.startswith((\"結論\", \"答案\")):\n",
    "                if \"true\" in line or \"是\" in line:\n",
    "                    return \"True\"\n",
    "                if \"false\" in line or \"否\" in line or \"不\" in line:\n",
    "                    return \"False\"\n",
    "                \n",
    "        negative_phrases = [\n",
    "            \"不是\", \"否\", \"不對\", \"false\", \"no\", \"不可以\",\n",
    "            \"不能\", \"不行\", \"never\", \"cannot\"\n",
    "        ]\n",
    "        positive_phrases = [\n",
    "            \"是\", \"對\", \"true\", \"yes\", \"可以\",\n",
    "            \"能\", \"行\", \"可以的\", \"沒問題\"\n",
    "        ]\n",
    "       # 去掉標點\n",
    "        text_nopunct = re.sub(f\"[{re.escape(string.punctuation)}]\", \" \", cleaned)\n",
    "\n",
    "        for phrase in negative_phrases:\n",
    "            if phrase in text_nopunct:\n",
    "                return \"False\"\n",
    "        for phrase in positive_phrases:\n",
    "            if phrase in text_nopunct:\n",
    "                return \"True\"\n",
    "        return \"UNKNOWN\"\n",
    "    \n",
    "    else:\n",
    "        return \"UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 讀檔 + 題型篩選\n",
    "df = pd.read_excel(\"test_questions.xlsx\")\n",
    "# test_df = df[df[\"type\"].isin([\"multiple_choice\", \"true_false\"])].copy()\n",
    "test_df = df[df[\"type\"].isin([\"multiple_choice\"])].copy()\n",
    "\n",
    "# 2. ★ 建立欄位（一定要在後面的篩選前先加）\n",
    "test_df[\"llm_response\"] = \"\"\n",
    "test_df[\"predicted\"]    = \"\"\n",
    "test_df[\"is_correct\"]   = 0\n",
    "\n",
    "# 3. 再依 domain 篩子集合\n",
    "# test_df = test_df[test_df[\"domain\"] == \"中醫\"].copy()\n",
    "test_df=test_df.head(3)\n",
    "\n",
    "# 4. 迴圈計分\n",
    "for idx, row in test_df.iterrows():\n",
    "    q  = row[\"question\"]\n",
    "    q_type = row[\"type\"]\n",
    "    gt = str(row[\"answers\"]).strip()\n",
    "\n",
    "    resp, _ = qa_system.display_response(q, q_type)\n",
    "\n",
    "    if not resp.strip():\n",
    "        print(f\"[WARN] id={row['id']}  LLM 回傳空白\")\n",
    "\n",
    "    pred = parse_llm_answer(resp, q_type)\n",
    "\n",
    "    test_df.at[idx, \"llm_response\"] = resp\n",
    "    test_df.at[idx, \"predicted\"]    = pred\n",
    "    test_df.at[idx, \"is_correct\"]   = int(pred.upper() == gt.upper())\n",
    "\n",
    "# 5. 計算 Accuracy\n",
    "overall_acc = test_df[\"is_correct\"].mean()\n",
    "\n",
    "print(\"\\n=== 每個 domain 的 Accuracy ===\")\n",
    "domain_stats = (\n",
    "    test_df.groupby(\"domain\")[\"is_correct\"]\n",
    "           .agg([\"count\", \"sum\"])\n",
    "           .reset_index()\n",
    "           .rename(columns={\"sum\": \"correct\"})\n",
    ")\n",
    "domain_stats[\"accuracy\"] = domain_stats[\"correct\"] / domain_stats[\"count\"]\n",
    "print(domain_stats.to_string(index=False, \n",
    "      formatters={\"accuracy\": \"{:.2%}\".format}))\n",
    "\n",
    "print(f\"\\nOVERALL Accuracy = {overall_acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== 測試結果 ===\")\n",
    "wq = test_df[test_df[\"is_correct\"] == 0].copy()\n",
    "# total = len(wq)\n",
    "# correct_count = wq[\"is_correct\"].sum()\n",
    "print(wq[[\"id\",\"type\",\"answers\",\"llm_response\",\"predicted\"]])\n",
    "# print(f\"\\n共 {total} 題，正確 {correct_count} 題，Accuracy = {accuracy:.2f}\")\n",
    "    \n",
    "# ======= 若需要將回覆結果輸出 CSV \n",
    "wq.to_excel(\"wq.xlsx\", index=False)\n",
    "print(\"結果已儲存 test_result.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
